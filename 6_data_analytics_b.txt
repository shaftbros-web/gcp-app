【問題1：災害対策のテスト手順自動化】要件: ミッションクリティカルなアプリのDR（災害復旧）テスト手順を、インフラのプロビジョニングと監視を含めGoogleネイティブの手法で自動化したい。Q1-1: gcloudスクリプトでプロビジョニングし、Activity Logsで監視・デバッグを行う。【 No 】理由: 自前のスクリプトは管理負荷が高く、Activity Logsは主にAPI監査用であり詳細なインフラ監視には適していません。Q1-2: gcloudスクリプトでプロビジョニングし、Stackdriverで監視・デバッグを行う。【 No 】理由: 監視にStackdriverを使用するのは正しいですが、インフラ構築に自前スクリプトを使うのはGoogle推奨のベストプラクティスではありません。Q1-3: Deployment Managerを使用してプロビジョニングし、Activity Logsで監視・デバッグを行う。【 No 】理由: インフラ構築ツールは正しいですが、監視ツールとしてActivity Logsを使用するのは不適切です。Q1-4: Deployment Managerを使用してプロビジョニングし、Stackdriverを使用して監視とデバッグを行う。【 Yes 】理由: インフラのコード化・自動化にはDeployment Manager（またはTerraform）を使用し、システムの稼働状態の監視にはStackdriver (Cloud Monitoring) を使用するのがDRテストのベストプラクティスです。【問題2：リソースの物理ロケーション制限】要件: 会社のポリシーに基づき、特定のリソースがGoogle Cloudの許可されたリージョンにのみデプロイされるよう物理的な作成場所を制限したい。Q2-1: Cloud Monitoringでアラートを設定し、他のリージョンで作成されたリソースを無効にする。【 No 】理由: アラートは事後検知であり、「作成自体を制限・防止する」という要件を満たせません。Q2-2: IAM条件を設定して、設定できるリソースを制限する。【 No 】理由: IAM条件では特定のユーザーのアクセス権に時間などのコンテキストを付与できますが、ロケーションの全体的な強制には適していません。Q2-3: 使用されていないリージョンのリソースのクォータを0に設定する。【 No 】理由: 手動でのクォータ管理は煩雑であり、新しいサービスが追加された際に制限が漏れる可能性があります。Q2-4: リソースの配備先（ロケーション）を制限する組織ポリシーを設定する。【 Yes 】理由: 組織ポリシーのリソースロケーション制約（Resource Location Restriction）を使用することで、許可されていないリージョンへのリソースデプロイをシステムレベルで完全にブロックできます。【問題3：別リージョンへのVMコピー展開】要件: 本番VMのコピーを管理・交換しやすい形で、別リージョンの別プロジェクトに新しいインスタンスとして迅速に展開したい。Q3-1: ルートディスクのスナップショットを作成し、それを別リージョンでのVM作成時に直接選択する。【 No 】理由: スナップショットから直接別リージョン・別プロジェクトでVMを起動するよりも、カスタムイメージ化する方が管理と展開の汎用性が高くなります。Q3-2: Linuxのddコマンドでイメージファイルを作成し、新しいVMを作成する。【 No 】理由: OS内部のコマンドで手動コピーを行うのはダウンタイムや不整合のリスクがあり、クラウドネイティブな手法ではありません。Q3-3: Linuxのddコマンドとnetcatを使用してルートディスクをストリーミングコピーする。【 No 】理由: 同様に、手動でのデータストリーミングは非効率かつエラーが発生しやすくなります。Q3-4: スナップショットを作成し、そこからCloud Storageにイメージファイルを作成し、それを元に新しいVMを作成する。【 Yes 】理由: スナップショットからカスタムイメージ（イメージファイル）を作成することで、グローバルリソースとして任意のリージョンやプロジェクトで簡単にVMのベースとして再利用・管理が可能になります。【問題4：侵入テスト（Cloud Function）の定期実行】要件: 毎週火曜日にリリースされるアプリに対し、セキュリティチームが作成した侵入テスト用のCloud Functionを定期的に自動実行したい。Q4-1: Cloud Tasksと、Cloud FunctionのトリガーとなるCloud Storageを設定する。【 No 】理由: リリースプロセスとテスト実行を連動させる要件に対し、Cloud Storageのファイル作成イベントをトリガーとするのは直接的な構成ではありません。Q4-2: IAMとConfidential Computingを設定して、Cloud Functionをトリガーする。【 No 】理由: これらはセキュリティ・暗号化関連の機能であり、スケジュール実行やイベント駆動のトリガー機能ではありません。Q4-3: Cloud Loggingシンクと、Cloud FunctionのトリガーとなるCloud Storageを設定する。【 No 】理由: ログをトリガーにするのは、定期的なアプリケーションのリリースに対するテスト実行パイプラインとして不適切です。Q4-4: Cloud Functionを起動するPub/Subキューに通知するようにデプロイジョブを設定する。【 Yes 】理由: アプリケーションのデプロイ（リリース）ジョブの完了時にPub/Subへメッセージを発行し、それをトリガーとして侵入テストのCloud Functionを起動させるのが、CI/CDに統合された最もスマートなイベント駆動アーキテクチャです。【問題5：IDのドメイン制限】要件: セキュリティチームの要請で、会社のドメイン外のIAMユーザーがGoogle Cloud組織内のプロジェクトで権限を取得することをシステム的に禁止したい。Q5-1: Cloud Schedulerで、ドメイン外のユーザーを削除するCloud Functionを1時間ごとに実行する。【 No 】理由: 定期実行のスクリプトでは、実行の合間にドメイン外ユーザーが権限を持ってしまう空白時間が生じます。Q5-2: サービスアカウントの作成を禁止する組織ポリシーを設定する。【 No 】理由: サービスアカウントの作成を禁止しても、外部のGmailアカウントなどがプロジェクトに招待されることは防げません。Q5-3: bashスクリプトとcronを用いて全プロジェクトのIAMをリストアップし外部ユーザーを削除する。【 No 】理由: スクリプトによる事後対応は管理オーバーヘッドが高く、予防的統制ではありません。Q5-4: ドメインごとにIDを制限する組織ポリシーを設定する。【 Yes 】理由: 組織ポリシーの「ドメイン制限の制約」を使用することで、指定したGoogle Workspaceドメイン以外のIDに対するIAMロールの付与を完全にブロック（予防）できます。【問題6：高可用性SLAを担保するレジリエンステスト】要件: 新規ユーザー解放に伴い、負荷増加やゾーン障害発生時でもアプリケーションがSLA(99.99%)を維持できるかレジリエンス（耐障害性）をテストしたい。Q6-1: リードレプリカを構成しKPIを監視しながら手動でフェイルオーバーをトリガーする。【 No 】理由: DBの手動フェイルオーバーだけでは、アプリケーション層のオートスケールやゾーン障害に対する包括的な耐障害性テストになりません。Q6-2: ユーザーグループを日ごとに大きくし、両方のゾーンのランダムなリソースを終了させる。【 No 】理由: 段階的な公開はカナリアリリースには有効ですが、急激なスパイクや障害に対するストレステストの要件をすぐには満たせません。Q6-3: 既存ユーザーの入力をキャプチャして再生し、一方のゾーンの全リソースを終了させる。【 No 】理由: 既存のユーザー入力の再生だけでは、未知の未登録ユーザーの予測不可能なトラフィックパターン（ランダム性）をシミュレートしきれません。Q6-4: ランダムなユーザー入力を作成して負荷を再生し、両ゾーンのランダムなリソースを停止させカオスエンジニアリングを導入する。【 Yes 】理由: 実シナリオに近いランダムなトラフィック負荷をかけつつ、意図的にリソースを停止（カオスエンジニアリング）させることで、オートスケールと自己修復機能がSLAを満たして正しく動作するかを最も確実にテストできます。【問題7：モノリシックからマイクロサービスへの移行の利点説明】要件: 拡張性と信頼性に欠けるモノリシックアプリを、マイクロサービスとマネージドサービスへ移行する価値（メリット）をリーダーに説得したい。Q7-1: このプロセスは、Migrate for Compute Engineで自動化できます。【 No 】理由: これはリフト＆シフト（VM移行）のツールであり、マイクロサービスへのアーキテクチャ再構築を自動化するものではありません。Q7-2: コストが大幅に削減され、基盤インフラの管理が容易になり、CI/CDを自動管理できるようになる。【 No 】理由: マイクロサービス化によってシステム全体の複雑さは増すことがあり、必ずしも「コストが大幅に削減」されるわけではありません。Q7-3: モノリシックなソリューションはDockerでコンテナ化しKubernetesにデプロイできる。【 No 】理由: コンテナ化するだけではモノリシックのままであり、マイクロサービスとしての利点（疎結合）を得られません。Q7-4: インフラとアプリの切り離し、新機能の独立したリリース、CI/CD・A/Bテストの管理、スケーリングが容易になる。【 Yes 】理由: マイクロサービス化の最大の利点は「サービスごとの独立した開発・テスト・デプロイ・スケーリング」が可能になり、ビジネスのアジリティとシステムの信頼性が向上することです。【問題8：Bigtableのパフォーマンス・負荷テスト】要件: Compute EngineとCloud Bigtableで構成されるサービスの拡張性を検証するため、QAチームが負荷テストツールを展開する際のベストプラクティスを含めたい。Q8-1: 負荷テストツールが本番環境に対して定期的に実行されるようスケジュールする。【 No 】理由: 本番環境への直接的な負荷テストは、実際の顧客に影響を与えるリスクがあるため避けるべきです。Q8-2: サービスが使用するすべてのサードパーティシステムが高負荷に対応できるか確認する。【 No 】理由: サードパーティへの意図しないDDoS攻撃になりかねず、テスト範囲から除外またはモック化すべきです。Q8-3: 負荷テストツールで再現するため、本番サービスのすべてのトランザクションを記録する機能を組み込む。【 No 】理由: 本番での全件記録はパフォーマンスの低下やプライバシー問題を引き起こすため不適切です。Q8-4: 負荷テストでCloud Bigtableの性能が検証されることを確認し、詳細なロギングとメトリクス収集機能を持たせる。【 Yes 】理由: マネージドサービスであっても、スキーマ設計に依存するBigtable自体のパフォーマンスを計測してボトルネックを特定することは必須であり、詳細なメトリクス収集は負荷テストの基本要件です。【問題9：本番デプロイのロールバック回数削減】要件: エラーによる計画外のロールバックを減らすため、QAプロセスの改善に加えて、アーキテクチャやデプロイ手法のアプローチを変更したい。Q9-1: リレーショナルデータベースをNoSQLデータベースで置き換える。【 No 】理由: データベースの種別変更はデータモデルの要件によるものであり、デプロイメントの安全性（ロールバック削減）の直接的な解決策ではありません。Q9-2: QA環境をカナリアリリースで置き換える。【 No 】理由: カナリアリリースは本番環境に対するデプロイ手法であり、QA環境自体を置き換える（なくす）ものではありません。Q9-3: リレーショナルデータベースシステムへの依存度を低減する。【 No 】理由: これ自体はデプロイの安全性を高める具体的なアーキテクチャ・リリースモデルの変更になりません。Q9-4: グリーン・ブルーのデプロイモデルを導入し、モノリシックなプラットフォームをマイクロサービスに分割する。【 Yes 】理由: Blue/Greenデプロイによりトラフィックの切り替えだけで安全にリリース・切り戻しが可能になり、マイクロサービス化により変更範囲（デプロイの爆発半径）を最小化できるため、ロールバックのリスクが激減します。【問題10：VMwareからのリフト＆シフト移行計画】要件: オンプレミスのVMware環境で稼働する多数のLinux VMを、Googleが推奨する方法（ベストプラクティス）に従ってCompute Engineに移行したい。Q10-1: 現在のVM環境を評価し、全VMにサードパーティ製エージェントをインストールして移行する。【 No 】理由: 個別のエージェントインストールは管理オーバーヘッドが大きく、GCPのネイティブな移行ツールの利点を活かしていません。Q10-2: アプリケーションリストに基づき、Migrate for Compute Engineで全VMを「個別に」移行する。【 No 】理由: 依存関係を持つVM群を個別に移行するとシステムが壊れるため、論理的なグループ（ウェーブ）単位で移行すべきです。Q10-3: 現在のVM環境を評価し、全ディスクのイメージを作成してインポートしVMを作成する。【 No 】理由: 手動でのイメージ作成とインポートはダウンタイムが長くなり、大規模な移行手法としては非効率です。Q10-4: 仮想マシンの評価を行い、移行プランを定義した上でMigrate for Compute EngineのRunBookを準備して移行を実行する。【 Yes 】理由: VMの依存関係と移行順序を定義した「RunBook」を使用し、グループ（ウェーブ）単位で計画的に移行を自動化するのが、GCP公式のベストプラクティスです。【問題11：PCI DSS準拠環境の構築プラットフォーム】要件: クレジットカード情報を扱うためPCI DSSに準拠する必要があるワークロードをクラウドに移行し、オーケストレーションにGKEを利用したい。Q11-1: App Engineは、GCPのコンピュートプラットフォームの中で唯一PCI DSSホスティングの認定を受けている。【 No 】理由: App Engineだけでなく、Compute EngineやGKEなど多くのサービスがPCI DSSの認定を受けています。Q11-2: GKEは共有ホスティングとみなされるため、PCI DSSで使用することはできない。【 No 】理由: GKE環境においても適切な分離設定を行うことでPCI DSSに準拠した構成が可能です。Q11-3: GCPはPCIに準拠していると認定されているため、すべてのサービスを無条件に使用できる。【 No 】理由: GCP自体が認定されていても、すべての個別サービスが認定されているわけではなく、ユーザー側でのセキュアな構成（責任共有モデル）も必要です。Q11-4: GKEとGCPは、PCI DSSに準拠した環境を構築するために必要なツールと認定を提供する。【 Yes 】理由: GKEを含む対象のGCPサービスはPCI DSSの要件を満たすためのセキュリティ機能とコンプライアンス認定を提供しており、適切な構成により準拠環境を構築できます。【問題12：Datastoreの新しいインデックスデプロイ】要件: App Engineアプリでエラーの原因となっているCloud Datastoreの不足インデックスを、作成したYAML設定ファイルから反映（デプロイ）したい。Q12-1: App EngineのデフォルトのCloud Storageバケットに設定ファイルをアップロードして検出させる。【 No 】理由: バケットにアップロードするだけではインデックスは自動生成されません。Q12-2: 組み込みのPythonモジュールでHTTPリクエストを作成し設定ファイルを送信する。【 No 】理由: コード内部から手動でインデックス設定を送信するのは一般的なデプロイ手順ではありません。Q12-3: Datastore Adminを使用して現在のインデックスを削除し、新しいファイルをアップロードする。【 No 】理由: 既存の正常なインデックスまで削除してしまい、アプリケーションに障害をもたらします。Q12-4: 設定ファイルを指定して `gcloud datastore create-indexes` コマンドを実行する。【 Yes 】理由: ローカルの構成ファイル（index.yamlなど）に基づいて新しいインデックスのみを安全に追加生成するには、このgcloudコマンドを使用するのが正しい手順です。【問題13：人気コンテンツ配信のパフォーマンス改善（CDN）】要件: GCEインスタンスからユーザーへ直接音楽ファイルをストリーミングしている環境で、人気曲へのアクセス集中による再生失敗（負荷）を解決したい。Q13-1: 人気曲をCloud SQLにコピーし、オーバーロード時にそこから取得するようにする。【 No 】理由: Cloud SQLはリレーショナルDBであり、大容量のメディアファイル（Blob）のストリーミング配信には不向きでコストもかかります。Q13-2: Cloud Filestoreボリュームを作成し、ダウンロードしてバックエンドGCEから配信する。【 No 】理由: ファイルストレージに変えても、GCEインスタンス自体へのネットワーク・処理負荷が集中する問題は解決しません。Q13-3: すべてのGCEにgcsfuseを使用してバケットをマウントし、GCEから配信する。【 No 】理由: GCEがストリーミングのボトルネックになるアーキテクチャ上の欠陥が残ったままです。Q13-4: MIGを作成し、Cloud Storageバケットと共にグローバルLBのバックエンドに設定し、バケット側でCloud CDNを有効にする。【 Yes 】理由: 静的な音楽ファイルをCloud Storageに置き、Cloud CDNを有効にしたロードバランサを経由させることで、エッジでキャッシュが効き、人気曲のトラフィックをGCEインスタンスから完全にオフロードしてパフォーマンスを劇的に改善できます。【問題14：GKEでの一貫したホスト名の維持】要件: GKE上のデータベースやクラスタ化されたワークロードにおいて、Podのスケーリングや再起動後も「一貫した永続的なホスト名」のセットを維持したい。Q14-1: ロールベースのアクセスコントロール (RBAC)【 No 】理由: RBACはAPIの権限管理を行うものであり、ネットワークやホスト名のアイデンティティ管理とは無関係です。Q14-2: 永続ボリューム (Persistent Volume)【 No 】理由: ストレージの永続化は行えますが、PodのネットワークID（ホスト名）を一貫させる機能はありません。Q14-3: コンテナの環境変数【 No 】理由: Podが再作成された際に新しいIPや名前が割り当てられるため、環境変数だけではDNSレベルの恒久的なホスト名解決はできません。Q14-4: StatefulSetsを使用する【 Yes 】理由: StatefulSetは、スケジュールされた場所や再起動に関わらず、Podに対して一意で永続的なネットワークID（ホスト名）とストレージを保証するため、ステートフルワークロードに最適です。【問題15：Pub/Subパブリッシングレイテンシ改善】要件: アプリケーションからPub/Subへのメッセージ発行（パブリッシュ）時にタイムアウトや数分間の待機（レイテンシ）が発生するのを改善したい。Q15-1: バックアップのPub/Subメッセージキューを作成する。【 No 】理由: キューを増やしても、クライアント側での発行時の送信遅延自体の解決にはなりません。Q15-2: サブスクライバーのプルモデルからプッシュモデルに移行する。【 No 】理由: これは「受信側（サブスクライバー）」の挙動の変更であり、「発行側（パブリッシャー）」のレイテンシ改善には寄与しません。Q15-3: Pub/Sub Total Timeoutのリトライ値を大きくする。【 No 】理由: タイムアウトエラーは減るかもしれませんが、レイテンシ（待機時間）自体はさらに長くなってしまいます。Q15-4: Pub/Subメッセージのバッチ処理をオフにする。【 Yes 】理由: パブリッシャーライブラリのバッチ処理（複数メッセージが溜まるか一定時間経つまで送信を待機する設定）を無効化することで、メッセージが即座にネットワークに送信され、パブリッシングのレイテンシを最小化できます。【問題16：VMからBigQueryへの接続エラー解消】要件: Compute Engine上のPythonスクリプトからBigQueryに接続する際のエラーを、Googleのベストプラクティスに従って修正したい。Q16-1: BigQueryのアクセススコープを有効にした新しいVMでスクリプトを実行する。【 No 】理由: アクセススコープはレガシーな権限付与の方法であり、現在はサービスアカウントに基づくIAM制御が推奨されています。Q16-2: `gcloud components install bq` でbqコンポーネントをインストールする。【 No 】理由: コマンドラインツール(bq)がないわけではなく、Pythonスクリプト（API）からの認証・権限エラーです。Q16-3: 最新のBigQuery APIクライアントライブラリをインストールする。【 No 】理由: ライブラリのバージョンではなく、接続するための認証情報（権限）の欠如が根本原因です。Q16-4: BigQueryへのアクセス権を持つ新しいサービスアカウントを作成し、そのユーザーで実行する。【 Yes 】理由: VMに対して適切なIAMロール（BigQueryアクセス権）を持つ専用のサービスアカウントを割り当てることが、API認証と権限付与のベストプラクティスです。【問題17：BigQueryの顧客提供暗号鍵（CMEK）】要件: 会社のセキュリティ要件に従い、Google Cloud外でインポートした暗号化キーを使用してBigQueryの機密データを保護したい。Q17-1: Cloud KMSで鍵を生成し、Cloud Storageに保存後、Dataflowで復号してBigQueryへ入れる。【 No 】理由: Google Cloud外で生成するという要件に反し、またパイプラインのアーキテクチャが冗長すぎます。Q17-2: Cloud KMSで新しいキーを生成し、BigQueryのCMEKオプションで設定する。【 No 】理由: クラウド内で鍵を生成（KMSで作成）してしまうため、「Cloud外で生成する」という要件を満たしません。Q17-3: Cloud KMSでキーをインポートし、GCSに保存、Dataflowで復号してBQへ入れる。【 No 】理由: Dataflowで手動で復号する処理は不要であり、BigQueryのネイティブな暗号化機能を活かしていません。Q17-4: Cloud KMSでキーをインポートし、顧客が提供するキーオプションを使用してBigQueryでデータセットを作成する。【 Yes 】理由: 外部で作成した鍵（キーマテリアル）をCloud KMSにインポートし、それをBigQueryデータセットの顧客管理の暗号鍵（CMEK）として指定することで、フルマネージドで透過的な暗号化・復号を実現しつつ要件を満たせます。【問題18：新規プロジェクトのコスト最小化（割引の活用）】要件: 需要が不明瞭なスタートアップのプロジェクトにおいて、インフラコストを自動的に最小化し、運用スタッフを増やさずにベストプラクティスを適用したい。Q18-1: 無料期間と継続利用割引を活用し、コスト管理スタッフを新たに配置する。【 No 】理由: スタッフの新規配置は人件費（コスト）の増大を招くため要件に反します。Q18-2: 無料期間とコミットメント利用割引を利用し、スタッフを配置する。【 No 】理由: 需要が不明瞭な段階で1〜3年の長期契約（コミットメント）を結ぶのはリスクが高く不適切です。Q18-3: 無料期間とコミットメント利用割引を利用し、チームにトレーニングを提供する。【 No 】理由: 同様に、需要が予測できないワークロードに対するコミットメント利用割引の適用は最適ではありません。Q18-4: 無料期間および継続利用割引を利用し、サービスコスト管理のトレーニングをチームに提供する。【 Yes 】理由: リソースの利用時間に応じて自動的に適用される「継続利用割引（Sustained Use Discount）」を活用し、チームにトレーニングを行って自己管理させるのが、不確実な需要に対する最もコスト効率の良いアプローチです。【問題19：サードパーティからの大容量データ移行】要件: 10TBのデータをサードパーティのオブジェクトストレージサービスからCloud Storageへ、最小コストかつ最速で移行したい。Q19-1: Google CloudからTransfer Applianceをリクエストする。【 No 】理由: アプライアンスの配送に数週間かかるため、10TB程度であればネットワーク経由の方が圧倒的に早く完了します。Q19-2: gsutil mvコマンドでデータを移動する。【 No 】理由: コマンドを実行するマシンのネットワーク帯域に依存し、マネージドな移行サービスではありません。Q19-3: オンプレミスにデータをダウンロードして、Cloud Storageにアップロードする。【 No 】理由: 2回の転送（ダウンロードとアップロード）が発生し、時間と通信コストの無駄です。Q19-4: Storage Transfer Serviceを使用してデータを移動する。【 Yes 】理由: クラウド間（サードパーティストレージからGCSへ）のデータ転送において、中継サーバーを立てることなくGoogleのバックボーンを活用して高速・安全・低コストに自動転送できるStorage Transfer Serviceが最適です。【問題20：信頼性の高いタスクスケジューリング】要件: GCEインスタンスで構成される分散システム上で、ネットワーク分断やVM停止に耐えうる信頼性の高いタスクスケジューリングを実装したい。Q20-1: GKEのCronサービスを使用してPub/Subに発行し、GCEでサブスクライブする。【 No 】理由: スケジューリングのためだけにGKEクラスタを構築・運用するのはオーバーヘッドが大きすぎます。Q20-2: App EngineのCronを使って、GCE上の処理サービスに直接HTTPでメッセージを発行する。【 No 】理由: 直接通信では、GCEインスタンスが停止していたりスケールアウトしている際の再送・分散処理が難しく、信頼性が低くなります。Q20-3: GKEのCronを使って、GCEサービスに直接発行する。【 No 】理由: 上記と同様の理由で不適切です。Q20-4: App Engine（またはCloud Scheduler）のCronを使用してPub/Subトピックに発行し、GCE上の処理サービスでサブスクライブする。【 Yes 】理由: フルマネージドなスケジューラでタスクを起動し、Pub/Subの非同期キューイングを介してバックエンド（GCE）に渡すことで、VMの一時的な停止や増減に影響されない極めて信頼性の高いジョブ実行アーキテクチャになります。【問題21：APIのバージョニング戦略】要件: 後方互換性のない大きな変更（改訂）を行うAPIにおいて、既存のクライアントコードを壊さずに安定性を確保したい。Q21-1: 現行APIにDEPRECATEDの接尾辞を付け、新APIに現在のバージョン番号を引き継ぐ。【 No 】理由: 既存クライアントのリクエスト先が突然新しい互換性のない仕様に変わってしまうため、システムが破壊されます。Q21-2: 古いAPIを置き換える1ヶ月前に、メーリングリストで変更をお知らせする。【 No 】理由: 猶予期間を設けても、エンドポイントを直接上書きしてしまえば期日に一斉にシステム障害が発生するリスクがあります。Q21-3: APIドキュメントの自動生成プロセスを作成し、CI/CDで更新する。【 No 】理由: ドキュメントの更新は重要ですが、APIの挙動自体の後方互換性を保証する技術的な解決策ではありません。Q21-4: 後方互換性のない変更ごとにバージョン番号を増加させるAPIのバージョン管理戦略を使用する。【 Yes 】理由: URIパス等にメジャーバージョン（v1, v2等）を含め、互換性を破る変更時はバージョンをインクリメントして別エンドポイントとして提供するのが、クライアントを保護するAPI設計のベストプラクティスです。【問題22：Cloud Shell環境でのユーティリティの永続化】要件: Cloud Shellにおいて、セッションが切れて再起動しても持続し、かつデフォルトの実行パスが通っている場所にカスタムツールを保存したい。Q22-1: /google/scripts に保存する。【 No 】理由: このディレクトリはCloud Shellの永続ストレージ領域外であり、セッション終了時に破棄されます。Q22-2: /usr/local/bin に保存する。【 No 】理由: ルートファイルシステムへの変更は一時的なVMのライフサイクルに紐づくため、再起動すると消えてしまいます。Q22-3: Cloud Storage に保存する。【 No 】理由: 永続化はされますが、毎回ダウンロードする手間がかかり、「デフォルトの実行パスにある」という要件を満たしません。Q22-4: ホームディレクトリ直下の ~/bin に保存する。【 Yes 】理由: Cloud Shellの `$HOME` ディレクトリはユーザー専用の永続ディスクとしてマウントされており再起動後も持続します。また `~/bin` はデフォルトでPATHに含まれているため最適です。【問題23：フォルダ権限（Project Owner）の制限】要件: 組織レベルで「Project Owner」権限を持つ開発チームに対し、特定のフォルダ（Finance）内のプロジェクトではリソース作成を禁止したい。Q23-1: FinanceフォルダにProject Viewerロールのみを付与する。【 No 】理由: IAMは親（組織）から許可が継承されるため、組織レベルのOwner権限が残っている限り、Financeフォルダでも編集・作成が可能です。Q23-2: ShoppingフォルダにProject Ownerロールのみを付与する。【 No 】理由: 同様に、組織レベルの権限が残っていれば制限になりません。Q23-3: FinanceにViewer、ShoppingにOwnerを付与する。【 No 】理由: 親レベルの強力な権限（和集合）が優先される原則に反しています。Q23-4: 組織レベルの開発チームのProject Ownerロールを削除し、許可したいフォルダ（Shopping）にのみProject Ownerを割り当てる。【 Yes 】理由: 権限を制限するには上位階層での広範な許可を削除し、必要な下位階層（フォルダ）でのみ再付与するアプローチが正しいIAMの設計です。【問題24：Cloud StorageのCMEKキーローテーション】要件: Dataprocで処理するCloud Storage上の機密データを暗号化し、かつコンプライアンス要件に従って「暗号化キー自体をローテーション」できるようにしたい。Q24-1: GPGキーペアを生成し、GPGキーで暗号化してアップロードする。【 No 】理由: クライアントサイドでの暗号化はデータ処理（Dataprocなど）とのシームレスな統合を妨げます。Q24-2: AES-256キーを生成し、顧客提供鍵 (CSEK) を使用する。【 No 】理由: CSEKはAPIリクエストのたびにキーを提供する必要があり、一元的なキーローテーション管理には適していません。Q24-3: Cloud KMSで鍵を作成し、KMSのencryptメソッドで手動暗号化する。【 No 】理由: 手動で暗号化・復号のロジックをアプリケーションに組み込む必要があり、透過的なデータ処理ができなくなります。Q24-4: Cloud KMSで鍵を作成し、バケットの暗号化キー（CMEK）に設定する。【 Yes 】理由: バケットのデフォルトキーにCloud KMSを指定することで、保存時の暗号化とDataproc等からの読み取り時の復号が完全に透過的になり、かつKMS側で容易にキーローテーション管理が可能になります。【問題25：App EngineのDBクエリ最小化（専用Memcache）】要件: Cloud SQLをバックエンドとするApp Engineアプリで、データベースの負荷を下げるためにクエリ発行数を最小限にしたい。Q25-1: Memcacheを「共有」にし、クエリハッシュキーでキャッシュをチェックする。【 No 】理由: 共有Memcacheはベストエフォートでありキャッシュ容量が保証されないため、キャッシュヒット率が安定せずDBの負荷低減策として確実ではありません。Q25-2: 共有Memcacheを使用し、1分ごとのcronタスクで全結果をキャッシュに投入する。【 No 】理由: 不要なクエリまで定期実行することになり、DB負荷の最小化に逆行します。Q25-3: 専用Memcacheを使用し、1分ごとのcronタスクで結果をキャッシュに投入する。【 No 】理由: 同様に、cronによる一括キャッシュは非効率です。Q25-4: 専用Memcacheを設定し、クエリハッシュのキーでキャッシュをチェックしてからCloud SQLにクエリを発行する。【 Yes 】理由: 容量が固定・保証される「専用Memcache」を使用し、リクエストの都度キャッシュを確認する（キャッシュアサイドアプローチ）ことで、データベースへの不要なクエリを最も効率的に削減できます。