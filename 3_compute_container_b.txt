ご要望にお応えして、提供された全ソースから「カテゴリ3：コンピューティングとコンテナ」に該当する問題（全20要件）を抽出しました。これらを「純粋な技術的・ビジネス的要件」と「その解決策（4パターンの選択肢）」にフォーカスし、それぞれの解決策で要件を満たせるかどうかを問うYes/No問題（全80問）に変換し、回答と理由をまとめました。---【カテゴリ3：コンピューティングとコンテナ】全80問の回答と理由【問題1：App Engine標準環境の選択】要件: 予測不可能なトラフィックを持つGo言語のAPIで、インフラの運用オーバーヘッドを最小限に抑えつつ信頼性を維持してデプロイしたい。Q1-1: Compute Engineのマネージドインスタンスグループ（MIG）を使用する。【 No 】理由: OSやインフラの管理が必要となり、運用オーバーヘッドを最小化する要件に反するため。Q1-2: コンテナ化してGoogle Kubernetes Engine（GKE）にデプロイする。【 No 】理由: Kubernetesクラスタ自体の管理オーバーヘッドが発生するため。Q1-3: カスタムランタイムを使用してApp Engineフレキシブル環境にデプロイする。【 No 】理由: Go言語は標準環境でサポートされており、コンテナベースのフレキシブル環境は標準環境に比べてインフラのオーバーヘッドが大きいため。Q1-4: App Engineの標準環境でアプリケーションを開発・デプロイする。【 Yes 】理由: サーバーレスのフルマネージド環境でありインフラ管理が不要。トラフィック急増時の即時スケールやゼロへのスケールダウンにも対応でき、運用負荷を最小化できるため。【問題2：営業時間外のVM停止によるコスト削減】要件: 営業時間中のみ使用される開発・ステージング環境のVMを最適化し、利用されない時間帯のコストを削減したい。Q2-1: プリエンプティブルVMを使用する。【 No 】理由: 最大24時間で強制終了するため、営業時間中にも停止するリスクがあり業務に支障をきたすため。Q2-2: MIGに配置しオートスケーリングを有効にする。【 No 】理由: トラフィックに基づく増減は可能ですが、「営業時間外に確実にゼロにする」というスケジュールベースの停止要件には適さないため。Q2-3: 本番VMでcronスクリプトをスケジュールし、gcloudコマンドでマシンタイプを小さくする。【 No 】理由: 本番VM内でスクリプトを管理することは運用負荷が高く、クラウドネイティブなベストプラクティスではないため。Q2-4: Cloud Schedulerを使用して、指定した時間にVMを停止・起動するCloud Functionをトリガーする。【 Yes 】理由: フルマネージドなジョブスケジューラを利用することで、運用負荷をかけずに確実に営業時間外のVMを停止でき、確実なコスト削減に繋がるため。【問題3：MIGの起動高速化】要件: 多数のOSパッケージ依存関係を持つアプリをMIGで構成する際、新規VMの起動時間（スタートアップ）を最小化したい。Q3-1: Deployment ManagerとAnsibleを使用してOSパッケージをインストールする。【 No 】理由: 起動するたびに多数のパッケージをインストールする処理が走り、起動時間が長くなるため。Q3-2: Terraformとスタートアップスクリプトを使用してOSパッケージをインストールする。【 No 】理由: スタートアップスクリプトによる都度インストールは起動のボトルネックになるため。Q3-3: Puppetを使用してOSパッケージをインストールする。【 No 】理由: 同様に、起動後の構成管理ツールによるインストール処理が起動時間を引き延ばすため。Q3-4: 必要なOSパッケージをすべて含んだカスタムVMイメージを作成し、Deployment ManagerでMIGを展開する。【 Yes 】理由: 依存関係をあらかじめ焼き込んだ「ゴールデンイメージ（カスタムイメージ）」を使用することで、起動時のインストール処理を省き、即座にVMを稼働させることができるため。【問題4：MIGの非破壊的アップデート】要件: MIGで実行中のインスタンスには影響を与えず（更新せず）、今後作成される新規インスタンスにのみ新しいアップデートを適用したい。Q4-1: プロアクティブアップデートモードでローリングアップデートを開始する。【 No 】理由: プロアクティブモードは、実行中の既存インスタンスも強制的に再作成・更新してしまうため要件に反します。Q4-2: 新規にローリングリスタート運転を開始する。【 No 】理由: 単なるリスタートでは新しいテンプレート（アップデート）は適用されません。Q4-3: 新しいローリングリプレースメント操作を開始する。【 No 】理由: 既存インスタンスを置き換えてしまうため要件に反します。Q4-4: Opportunistic update（日和見更新）モードを選択してローリングアップデートを開始する。【 Yes 】理由: このモードを選択すると、既存のインスタンスには触れず、オートスケーラーなどによって「新しく作成されるインスタンス」にのみ新テンプレートが適用されるため。【問題5：インフラ管理不要の大規模Webホスティング】要件: 数百万人の同時ユーザーをサポートするWebアプリを、インフラの構築・維持を意識せずにコードの作成に専念してデプロイしたい。Q5-1: Compute Engineを使用する。【 No 】理由: OSやネットワーク、スケーリングの設計などインフラの構築と維持が必要なため。Q5-2: Google Kubernetes Engineを使用する。【 No 】理由: クラスタやノードプールの管理が必要になり、完全にインフラ管理から解放されるわけではないため。Q5-3: Cloud Endpointsを使用する。【 No 】理由: これはAPIゲートウェイ管理ツールであり、Webアプリのホスティング基盤ではないため。Q5-4: Google App Engineを使用する。【 Yes 】理由: App Engineはインフラ管理が一切不要なフルマネージドPaaSであり、数百万のトラフィック増減にも自動でスケール対応できるため。【問題6：App EngineでのA/Bテスト/カナリアリリース】要件: App Engineアプリの現行バージョンを置き換える前に、本番トラフィックの一部だけを新バージョンに流してテストしたい。Q6-1: 新しいVPCに配置し、グローバルHTTPロードバランサでトラフィックを分割する。【 No 】理由: App EngineはVPC内にデプロイするものではなく、自前でLBを構成するのは冗長なため。Q6-2: 新しいApp Engineアプリとしてデプロイし、グローバルHTTPロードバランサで分割する。【 No 】理由: 「別のアプリ」としてデプロイするとドメインが分かれる等、スマートなトラフィック分割にならないため。Q6-3: Instance Group Updaterを使用して部分的なロールアウトを作成する。【 No 】理由: これはCompute Engine (MIG) の機能であり、App Engineには適用できません。Q6-4: 新しいバージョンとしてデプロイし、新旧バージョン間でトラフィックを分割（Traffic Splitting）する。【 Yes 】理由: App Engineにネイティブに備わっているトラフィック分割機能を使用することで、パーセンテージ指定で簡単にA/Bテストやカナリアリリースを実現できるため。【問題7：バッチ処理のコスト削減とコンプライアンス要件】要件: タイムクリティカルではないバッチ処理のコストを削減しつつ、HIPAAに準拠していないGCPサービスの使用を確実に停止したい。Q7-1: 標準VMをプロビジョニングし、HIPAA非準拠のサービスを使用中止にする。【 No 】理由: 標準VMでは「コストの削減」という要件を最大化できないため。Q7-2: プリエンプティブルVMをプロビジョニングし、HIPAA非準拠のGCPサービスの使用を中止する（無効化はしない）。【 No 】理由: 使用を控えるだけでは誤って使用されるリスクがあり、コンプライアンス上は「無効化」することが推奨されるため。Q7-3: 同じリージョンで標準VMを提供し、HIPAA非準拠APIを無効にして使用中止する。【 No 】理由: コスト削減の観点でプリエンプティブルVMを利用していないため。Q7-4: プリエンプティブルVMをプロビジョニングし、HIPAA非準拠のすべてのGCPサービスとAPIを無効にしてから使用を中止する。【 Yes 】理由: バッチ処理に安価なプリエンプティブルVMを使うことでコストを大幅に削減でき、非準拠APIをシステムレベルで「無効化」することでHIPAAコンプライアンスを確実に担保できるため。【問題8：外部委託向けの運用オーバーヘッド最小化】要件: アプリの運用を外部チームに委託するため、運用オーバーヘッドが最小で、ステージングから本番への自律的なプロモートが容易な環境を選びたい。Q8-1: Compute Engineを利用する。【 No 】理由: OSパッチやセキュリティ管理など、運用オーバーヘッドが最も大きいため。Q8-2: Google Kubernetes Engineを利用する。【 No 】理由: クラスタ管理のオーバーヘッドが発生するため。Q8-3: GKE オンプレミスを利用する。【 No 】理由: オンプレミスのインフラ管理が残るため要件に反します。Q8-4: Google App Engineを利用する。【 Yes 】理由: サーバーレスで運用オーバーヘッドがゼロに近く、バージョン管理やトラフィック移行が容易なため、外部チームでも安全かつ自律的に運用できるため。【問題9：GKEのオートスケール競合回避】要件: GKEクラスタにおいて、PodのCPU負荷に応じて自動的にノードを追加・削除（オートスケール）したい。Q9-1: デプロイメントを作成し、GCPコンソールからクラスタの「マネージドインスタンスグループのオートスケーリング」を有効にする。【 No 】理由: GKEのノード群に対してCompute EngineのMIGオートスケーラーを直接有効にすると、GKE側のスケジューラーと競合するため非推奨です。Q9-2: HPAを設定し、gcloudコマンドでクラスタの「マネージドインスタンスグループのオートスケーリング」を有効にする。【 No 】理由: 同様に、GKEノードに対してCompute Engine側のオートスケーラーを手動で有効化してはいけません。Q9-3: デプロイメントを作成し、gcloudコマンドでクラスタのオートスケーラーを有効にする。【 No 】理由: HPA（Horizontal Pod Autoscaler）の設定が抜けているため、負荷に応じたPod数の増減が行われません。Q9-4: HorizontalPodAutoscaler (HPA) を目標CPU使用率で設定し、GCPコンソールからCluster Autoscalerを有効にする。【 Yes 】理由: Podの増減を管理するHPAと、ノードの増減を管理するGKEネイティブのCluster Autoscalerを組み合わせるのが、競合を起こさない正しい設定手順であるため。【問題10：Cloud Runでのカナリアリリース】要件: Cloud Runの新バージョンを、本番トラフィックの少量のサブセットで評価し、ロールアウトを続行するか決定したい。Q10-1: 新しいサービスとしてデプロイし、前段にCloud Load Balancingを追加する。【 No 】理由: サービスを分けてLBで管理するのは複雑になり、Cloud Runのネイティブ機能を活かせていないため。Q10-2: 新しいサービスとしてデプロイし、Traffic Directorでトラフィックの少割合をルーティングする。【 No 】理由: Traffic Directorは主にサービスメッシュ用であり、単一のCloud Runサービスのカナリアリリースには適していません。Q10-3: Cloud Buildの置換変数を使用してトラフィック割合を設定する。【 No 】理由: CI/CDツール側での変数置換はトラフィック制御機能そのものではありません。Q10-4: 新しいリビジョンをデプロイし、リビジョン間のトラフィックパーセンテージを設定する。【 Yes 】理由: Cloud Runには複数のリビジョン間でトラフィックを分割する機能がネイティブに備わっており、これを設定するだけでカナリアリリースが実現できるため。【問題11：GKEインフラのゼロからのデプロイ】要件: インフラがまだない状態から、提供されたKubernetes Deploymentファイルを使ってアプリをデプロイしたい。Q11-1: kubectlを使用してクラスタを作成し、kubectlでデプロイメントを作成する。【 No 】理由: `kubectl`コマンドはKubernetes内のリソース操作用であり、GCP上のクラスタ自体を作成することはできないため。Q11-2: gcloudを使用してクラスタを作成し、Deployment Managerでデプロイメントを作成する。【 No 】理由: Deployment ManagerはGCPリソース管理用であり、Kubernetes内部のDeployment作成には適していません。Q11-3: kubectlを使用してクラスタを作成し、Deployment Managerでデプロイメントを作成する。【 No 】理由: コマンドの用途がどちらも間違っているため。Q11-4: gcloudを使用してクラスタを作成し、kubectlを使用してデプロイメントを作成する。【 Yes 】理由: GCPのリソースであるクラスタの作成は`gcloud`で行い、クラスタ内のコンテナ構成であるデプロイメントの作成はK8s標準の`kubectl`で行うのが正しい手順であるため。【問題12：GKEのクラスタオートスケーリング有効化コマンド】要件: 既存のGKEクラスタにおいて、リクエスト数に応じてノード数を自動的にスケーリングさせたい。Q12-1: gcloud container clusters resize コマンドを使用する。【 No 】理由: `resize`コマンドは静的にクラスタのノード数を変更するものであり、「自動スケーリング」を有効化するものではありません。Q12-2: gcloud container clusters create コマンドで新しいクラスタを作成する。【 No 】理由: 「既存のクラスタ」を変更する要件に反します。Q12-3: gcloud compute instances add-tags コマンドでインスタンスにタグを追加する。【 No 】理由: タグを追加してもオートスケーリング機能は有効になりません。Q12-4: gcloud container clusters update コマンドで --enable-autoscaling フラグを指定する。【 Yes 】理由: 既存クラスタの設定を更新する`update`コマンドに`--enable-autoscaling`を付与することで、クラスタの自動スケーリングが正しく有効化されるため。【問題13：GKE内部のサービスディスカバリ】要件: GKE内部で完結する複数のマイクロサービス間で、レプリカ数に関わらず一貫したDNS名で相互アクセスできるようにしたい。Q13-1: 各マイクロサービスをPodとしてデプロイし、ServiceのDNS名を使用する。【 No 】理由: 裸のPodとしてデプロイすると、障害時に自動復旧されないため適切ではありません。Q13-2: 各マイクロサービスをDeploymentとしてデプロイし、Ingress IPアドレス名を使用する。【 No 】理由: Ingressはクラスタ外部からのアクセス用であり、内部で完結するアクセスには不要かつ非効率です。Q13-3: 各マイクロサービスをPodとしてデプロイし、Ingress IPアドレスを使用する。【 No 】理由: Pod単体の運用は非推奨であり、内部通信にIngressを使うのも誤りです。Q13-4: 各マイクロサービスをDeploymentとしてデプロイし、Serviceを使用して公開し、ServiceのDNS名を使用する。【 Yes 】理由: Deploymentで可用性を担保し、Kubernetesの「Service」機能を作成することで、kube-dnsによってクラスタ内部で一貫したDNS名によるルーティングが実現できるため。【問題14：Pub/Subバックログに基づくK8sオートスケール】要件: GKE上のアプリがPub/Subのメッセージ処理に追いつかず遅延しているため、I/O処理をスケールアップさせたい。Q14-1: クラスタ作成時に --enable-autoscaling フラグを使用する。【 No 】理由: クラスタノードのスケールだけでは、処理を行うPod自体を増やすトリガーにはなりません。Q14-2: kubectl autoscale deployment でCPUパーセンテージに基づく設定を行う。【 No 】理由: I/O待機（メッセージ待ち）が中心のアプリではCPU負荷が上がりにくく、CPU基準のスケールでは間に合いません。Q14-3: subscription/push_request_latenciesメトリックに基づいて構成する。【 No 】理由: このメトリクスはPush型のエンドポイント遅延を示すものであり、処理の滞留量（バックログ）を示すものではありません。Q14-4: subscription/num_undelivered_messages（未配信メッセージ数）メトリックに基づいて構成する。【 Yes 】理由: Cloud Monitoringに連携されるこのメトリクス（バックログ数）をトリガーにHPAを設定することで、キューに溜まった仕事量に応じて正確にPodをスケールできるため。【問題15：Hadoopジョブのクラウド移行によるコスト最小化】要件: データサイエンスチームのHadoopジョブを、コード基盤を変更せずに、インフラ管理の手間とコストを最小化してGCPに移行したい。Q15-1: Compute Engineに手動でHadoopクラスタを展開し、標準インスタンスを使用する。【 No 】理由: 手動展開はインフラ管理の手間が大きく、標準インスタンスではコスト最小化の要件を満たしません。Q15-2: Compute Engineに手動でHadoopクラスタを展開し、プリエンプティブルインスタンスを使用する。【 No 】理由: コストは下がりますが、手動展開によるインフラ管理のオーバーヘッドが残ります。Q15-3: 標準ワーカーインスタンスを使用してDataprocクラスタを作成する。【 No 】理由: Dataprocで手間は省けますが、標準ワーカーではコスト最小化の要件を満たしきれません。Q15-4: プリエンプティブルワーカーインスタンスを使用してDataprocクラスタを作成する。【 Yes 】理由: マネージドHadoop環境であるDataprocを利用することで基盤変更と管理の手間を省き、ワーカーに安価なプリエンプティブルVMを指定することでコストを最小化できるため。【問題16：コンピュートのリージョン障害耐性】要件: Compute Engine上のアプリにおいて、大規模なリージョン障害が発生した場合に別リージョンへフェイルオーバーさせたい。Q16-1: 同じリージョン内の別ゾーンに配置し、HTTPロードバランサでフェイルオーバーする。【 No 】理由: リージョン全体がダウンした場合には対応できないため。Q16-2: 別プロジェクトの別リージョンに配置し、HTTPロードバランサでフェイルオーバーする。【 No 】理由: ロードバランサのバックエンドとしてシームレスにフェイルオーバーさせるには、同一プロジェクト内にリソースが存在する必要があります。Q16-3: 単一のインスタンスを2つ別リージョンにデプロイしフェイルオーバーする。【 No 】理由: 単一インスタンスではゾーン障害への耐性やスケーリング能力に欠けます。Q16-4: 同じプロジェクト内の異なるリージョンに2つのMIGをデプロイし、HTTPロードバランサを使用してフェイルオーバーする。【 Yes 】理由: 同一プロジェクト内の別リージョンにMIG（マネージドインスタンスグループ）を配置し、グローバルロードバランサで束ねることで、リージョン規模の障害時にも自動的かつ確実なフェイルオーバーが実現するため。【問題17：OSパッチ管理の自動化】要件: 複雑な設定が必要なDebian Linux環境のVMにおいて、OSのアップデートを最小限の手動操作でインストール・管理したい。Q17-1: 更新のたびに最新イメージからインスタンスを作成し、SSHで設定を繰り返す。【 No 】理由: 手動操作が極めて多く、要件に反します。Q17-2: 最新イメージでインスタンステンプレートを作成し、起動スクリプトで設定を繰り返す。【 No 】理由: 再作成に伴うオーバーヘッドがあり、長期稼働VMのパッチ管理としてはスマートではありません。Q17-3: Dockerコンテナを作成し、更新のたびにGKE上で再起動する。【 No 】理由: OSの広範な設定が必要なレガシーアプリの場合、コンテナ化自体が困難であったりアーキテクチャの大幅な変更が必要になります。Q17-4: DebianのCompute Engineインスタンスを作成して設定後、OS Patch Managementを使用してアップデートを自動適用する。【 Yes 】理由: OS Patch Managementサービスを利用することで、稼働中のVMに対してスケジュールベースでパッチ適用を自動化でき、手動操作を最小限に抑えられるため。【問題18：ピーク時のMIGスケールアウト高速化】要件: ピーク時に処理が遅延するステートレスアプリのパフォーマンスを最適化するため、MIGによるスケールアウト時の新規VM起動を高速化したい。Q18-1: スナップショットから直接カスタムイメージを作り、それを利用する（テンプレートを介さない）。【 No 】理由: MIGを作成するには必ずインスタンステンプレートを経由する必要があります。Q18-2: 既存ディスクのスナップショットを作成し、スナップショットからインスタンステンプレートを作成する。【 No 】理由: スナップショットから直接テンプレートを作って起動すると、起動のたびにディスクの復元処理が走り起動が遅くなります。Q18-3: 既存ディスクからインスタンステンプレートを作成し、そこからイメージを作る。【 No 】理由: 作成の順序（依存関係）が間違っています。Q18-4: 既存ディスクからカスタムイメージを作成し、そのイメージを基にインスタンステンプレートを作成してオートスケールMIGを構成する。【 Yes 】理由: カスタムイメージ（ゴールデンイメージ）を作成してテンプレートに指定することで、スナップショットからの復元よりVMの起動時間が圧倒的に早くなり、ピーク時のスケールアウトに即座に対応できるため。【問題19：単一テナンシーによるワークロードの物理的隔離】要件: コンプライアンス要件に従い、異なるクライアントのワークロードを物理的に分離された専用ハードウェア（単一テナントノード）に正しく配置したい。Q19-1: Compute Engine作成時にネットワークタグとしてノード名を追加する。【 No 】理由: ネットワークタグはファイアウォール制御等に使用するもので、ホストの物理的な配置を制御するものではありません。Q19-2: Compute Engine作成時にノードグループ名に基づくノードアフィニティラベルを使用する。【 No 】理由: アフィニティラベルは「ノードグループ」ではなく個別の「ノードテンプレート（ノード）」に対して指定する必要があります。Q19-3: Compute Engine作成時にネットワークタグとしてノードグループ名を追加する。【 No 】理由: 同様にネットワークタグでは物理配置を制御できません。Q19-4: Compute Engine作成時に、正しいノードでホストされるようノード名に基づくノードアフィニティラベルを使用する。【 Yes 】理由: Sole-tenant nodes（単一テナントノード）において、特定クライアントのVMを特定の物理サーバーに配置するには「ノードアフィニティラベル」を使用するのが正しい設定手法であるため。【問題20：一時的なテスト環境の高速化とスケーリング】要件: 完了までに数時間かかるC++のテストスイート（Linuxカスタムアプリ）をクラウドに移行し、テスト時間を短縮したい。Q20-1: Google App EngineとStackdriverを使用する。【 No 】理由: カスタムのC++ LinuxアプリはApp Engineの標準的なWeb実行環境には適していません。Q20-2: DataprocでHadoopジョブとして各テストを処理する。【 No 】理由: 単純なLinuxアプリケーションのテストスイートをHadoopジョブに作り直すのはオーバーヘッドが大きすぎます。Q20-3: Compute Engineのアンマネージドインスタンスグループとネットワークロードバランサを使用する。【 No 】理由: アンマネージドインスタンスグループはオートスケーリングをサポートしておらず、テスト時の柔軟なリソース追加要件を満たしません。Q20-4: オートスケーリング機能付きのCompute Engineマネージドインスタンスグループ(MIG)を使用する。【 Yes 】理由: オートスケーリングを備えたMIGにテスト処理を並列化させることで、必要な時だけ大量のコンピュートリソースを確保し、テスト時間を大幅に短縮できるため。