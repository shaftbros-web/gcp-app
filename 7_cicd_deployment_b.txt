ご要望にお応えして、提供された新たなソース（study4.md）に記載されている全20要件を「カテゴリ7」として抽出し、「純粋な技術的・ビジネス的要件」と「その解決策」の正誤を問うYes/No問題（全80問）に変換いたしました。各回答には理由も添えております。---【カテゴリ7：インフラ・開発・運用に関する総合問題】全80問の回答と理由【問題1：Pub/Subへの安全なアクセス認証】要件: VM上のアプリケーションからCloud Pub/Subへメッセージを発行する際、Google推奨のベストプラクティスに従って認証を行いたい。Q1-1: VMサービスアカウントがCloud Pub/Subへのアクセスを持たないようにし、アクセススコープを使用する。【 No 】理由: アクセススコープはレガシーな手法であり、現在はIAMベースのサービスアカウントによる権限付与が推奨されています。Q1-2: OAuth2アクセストークンを生成し暗号化してCloud Storageに保存し、VMからアクセスさせる。【 No 】理由: トークンを自前で保管・管理するのは漏洩リスクがあり運用オーバーヘッドが高くなります。Q1-3: Cloud Functionを使用してゲートウェイを作成し、サービスアカウントにロールを付与する。【 No 】理由: 直接Pub/Subへアクセスできる要件に対し、無駄な中継コンポーネントを挟むのは非効率です。Q1-4: VMにアタッチされたサービスアカウントに適切なCloud Pub/SubのIAMロールが付与されていることを確認する。【 Yes 】理由: GCPのリソース間通信（VMからPub/Sub）においては、VMに割り当てられたサービスアカウントに必要なIAMロールを付与して認証させるのが最も安全で公式に推奨されるベストプラクティスです。【問題2：Cloud StorageのCMEKキーローテーション】要件: Dataprocで処理するCloud Storage上の機密データを暗号化し、かつコンプライアンス要件に従って暗号化キー自体をローテーションできるようにしたい。Q2-1: GPGキーペアを生成し、GPGキーで手動で暗号化してアップロードする。【 No 】理由: クライアントサイドでの暗号化はデータ処理（Dataprocなど）とのシームレスな統合を妨げます。Q2-2: AES-256キーを生成し、顧客提供鍵 (CSEK) を使用する。【 No 】理由: CSEKはAPIリクエストのたびにキーを提供する必要があり、一元的なキーローテーション管理には適していません。Q2-3: Cloud KMSで鍵を作成し、KMSのencryptメソッドで手動暗号化する。【 No 】理由: 手動で暗号化・復号のロジックをアプリケーションに組み込む必要があり、透過的なデータ処理ができなくなります。Q2-4: Cloud KMSで鍵を作成し、バケットの暗号化キー（CMEK）に設定する。【 Yes 】理由: バケットのデフォルトキーにCloud KMSを指定することで、保存時の暗号化とDataproc等からの読み取り時の復号が完全に透過的になり、かつKMS側で容易にキーローテーション管理が可能になります。【問題3：Cloud SQLの負荷・容量最適化】要件: Cloud SQLのストレージ不足を回避し、CPU使用率を維持しつつ、レプリケーションラグを減らしたい。Q3-1: ストレージが75%を超えたらStackdriverアラートを作成して手動追加し、memcachedを導入し、32コアマシンタイプに変更する。【 No 】理由: 手動での容量追加は運用負荷が高く、自動増加機能を使うべきです。Q3-2: インスタンスのストレージ自動増加を有効にし、32コアに変更してCPU使用率を下げ、レプリケーションラグアラートでmemcacheを導入する。【 No 】理由: キャッシュの導入ではDB自体のレプリケーションラグの根本解決（書き込み負荷の分散）にはなりません。Q3-3: ストレージが75%を超えたらアラートを作成して手動追加し、memcachedを導入し、レプリケーション遅延アラートで32コアに変更する。【 No 】理由: ストレージが手動管理になっており不適切です。Q3-4: ストレージの自動増加を有効にし、CPU超過アラートでインスタンスタイプを変更し、レプリケーション遅延アラートでデータベースをシャード化する。【 Yes 】理由: ストレージ不足は自動増加で解決し、CPU維持はアラート検知とマシンタイプ変更で対応し、レプリケーション遅延は「シャーディング」で分割解決するのがアーキテクチャとして正しいアプローチです。【問題4：開発環境インフラのコスト可視化と最適化】要件: 開発VMリソースのコストを財務部門に可視化しつつ、頻繁な起動/停止に備えてVMの状態を保持したい。Q4-1: VMのCPU使用率のラベルを適用し、BigQueryの請求書エクスポートに含める。【 No 】理由: CPU使用率といったメトリクスは請求データと直接リンクするものではありません。Q4-2: すべての状態をローカルSSDに保存し、スナップショットを取ってVMを終了させる。【 No 】理由: ローカルSSDはVM停止時にデータが消失するため、状態を永続化する用途には不適切です。Q4-3: すべての永続ディスクに `--auto-delete` フラグを使用し、VMを終了させる。【 No 】理由: このフラグではVM停止時にディスクも削除されてしまい、状態を持続させる要件を満たせません。Q4-4: すべての永続ディスクに `--no-auto-delete` フラグを使用してVMを停止し、BigQuery請求書エクスポートとラベルでコストを関連付ける。【 Yes 】理由: `--no-auto-delete` でディスクと状態を維持しつつVMのコンピューティング課金を止め、さらにラベルとBigQueryエクスポートを組み合わせることで財務部門への確実なコスト可視化が実現します。【問題5：GKEのクラスタオートスケーリング有効化】要件: 既存のGKEクラスタにおいて、アプリケーションのトラフィック増加に応じてノード数を自動的にスケーリングさせたい。Q5-1: `gcloud container clusters resize CLUSTER_NAME --size=10` コマンドを使用する。【 No 】理由: `resize`コマンドは静的にクラスタのノード数を変更するものであり、「自動スケーリング」を有効化するものではありません。Q5-2: `gcloud container clusters create` コマンドでオートスケーリング付きの新しいクラスタを作成する。【 No 】理由: 「既存のクラスタ」を変更する要件に反します。Q5-3: `gcloud compute instances add-tags` コマンドでインスタンスにタグを追加する。【 No 】理由: タグを追加してもオートスケーリング機能は有効になりません。Q5-4: `gcloud container clusters update CLUSTER_NAME --enable-autoscaling` コマンドを使用して既存のクラスタを更新する。【 Yes 】理由: 既存クラスタの設定を更新する`update`コマンドに`--enable-autoscaling`と最小/最大ノード数を付与することで、クラスタの自動スケーリングが正しく有効化されます。【問題6：Anthos Service MeshのSLO監視とアラート】要件: リクエストレイテンシが特定の閾値を超えた場合にアラートを出すSREプラクティスをAnthosクラスタに実装したい。Q6-1: プロジェクトでCloud Trace APIを有効にし、Cloud Traceのメトリクスに基づいてアラートを送信する。【 No 】理由: Cloud Traceは単一リクエストのドリルダウン分析用であり、サービス全体の可用性やSLO評価アラートの基盤としては適していません。Q6-2: Cloud Profilerを使用してカスタムメトリックを作成し、アラートを出す。【 No 】理由: ProfilerはCPUやメモリなどのコードレベルのパフォーマンス解析用であり、ネットワークレイテンシのSLO監視用ではありません。Q6-3: Anthos Config ManagementでSLOとアラートポリシーを定義するyamlファイルを作成する。【 No 】理由: 設定管理ツールではSLOに基づく動的なアラート監視システムの構成は直接的には行えません。Q6-4: Anthos Service Meshをインストールし、Cloud ConsoleでService Level Objective (SLO)を定義してアラートポリシーを作成する。【 Yes 】理由: Anthos Service Meshは各サービスのレイテンシなどのメトリクスを自動収集し、コンソール上で直接サービスレベル目標（SLO）とそれに基づくエラーバジェットアラートを定義できます。【問題7：OSパッチ管理の自動化】要件: 複雑な設定が必要なDebian Linux環境のVMにおいて、OSのアップデートを最小限の手動操作でインストール・管理したい。Q7-1: 最新イメージでインスタンスを作成し手動でアプリケーションをインストール・設定するプロセスを繰り返す。【 No 】理由: 手動操作が極めて多く、要件に反します。Q7-2: 最新イメージでインスタンステンプレートを作成し、起動スクリプトで設定を繰り返す。【 No 】理由: 再作成に伴うオーバーヘッドがあり、長期稼働VMのパッチ管理としてはスマートではありません。Q7-3: DebianベースのDockerコンテナを作成し、新しいアップデートごとにGKE上でコンテナを再起動する。【 No 】理由: OSの広範な設定が必要なレガシーアプリの場合、コンテナ化自体が困難であったりアーキテクチャの大幅な変更が必要になります。Q7-4: DebianのCompute Engineインスタンスを作成して設定後、OS Patch Managementを使用してアップデートを自動適用する。【 Yes 】理由: OS Patch Managementサービスを利用することで、稼働中のVMに対してスケジュールベースでパッチ適用を自動化でき、手動操作を最小限に抑えられます。【問題8：ピーク時のMIGスケールアウト高速化】要件: ピーク時に処理が遅延するステートレスアプリのパフォーマンスを最適化するため、MIGによるスケールアウト時の新規VM起動を高速化したい。Q8-1: 既存ディスクのスナップショットを作成し、スナップショットからカスタムイメージを作り、それを利用する（テンプレートを介さない）。【 No 】理由: MIGを作成するには必ずインスタンステンプレートを経由する必要があります。Q8-2: 既存のディスクのスナップショットを作成し、スナップショットからインスタンステンプレートを作成してオートスケールMIGを構成する。【 No 】理由: スナップショットから直接テンプレートを作って起動すると、起動のたびにディスクの復元処理が走り起動が遅くなります。Q8-3: 既存のディスクからインスタンステンプレートを作成し、インスタンステンプレートからカスタムイメージを作成する。【 No 】理由: 作成の順序（依存関係）が間違っています。Q8-4: 既存のディスクからカスタムイメージを作成し、そのイメージを基にインスタンステンプレートを作成してオートスケールMIGを構成する。【 Yes 】理由: 依存関係を含んだカスタムイメージ（ゴールデンイメージ）を作成してテンプレートに指定することで、スナップショットからの復元よりVMの起動時間が圧倒的に早くなり、即座にトラフィック増に対応できます。【問題9：単一テナンシーによるワークロードの物理的隔離】要件: コンプライアンス要件に従い、異なるクライアントのワークロードを物理的に分離された専用ハードウェア（単一テナントノード）に正しく配置したい。Q9-1: Compute Engine作成時にネットワークタグとしてノード名を追加する。【 No 】理由: ネットワークタグはファイアウォール制御等に使用するもので、ホストの物理的な配置を制御するものではありません。Q9-2: Compute Engine作成時にノードグループ名に基づくノードアフィニティラベルを使用する。【 No 】理由: アフィニティラベルはノードグループ全体ではなく、個別の「ノードテンプレート（ノード）」に対して指定する必要があります。Q9-3: Compute Engine作成時にネットワークタグとしてノードグループ名を追加する。【 No 】理由: 同様にネットワークタグでは物理配置を制御できません。Q9-4: 正しいノード上で各ワークロードをホストするために、Compute Engineインスタンスの作成時にノード名に基づくノードアフィニティラベルを使用する。【 Yes 】理由: Sole-tenant nodes（単一テナントノード）において、特定クライアントのVMを特定の物理サーバーに配置するには「ノードアフィニティラベル」を使用するのが正しい設定手法です。【問題10：Cloud SQLのフェイルオーバー機能テスト】要件: トラフィックが多い時間帯にデータベースクラッシュ時にレプリカがマスターに昇格しなかった事象の再発を防ぎたい。Q10-1: 別のデータベースを使用する。【 No 】理由: DBを変更しても、システム切り替えテストを行わなければ高可用性が担保される確証は得られません。Q10-2: より定期的にデータベースのスナップショットを作成する。【 No 】理由: スナップショットはデータ復旧用であり、自動フェイルオーバー機構の健全性をテストするものではありません。Q10-3: データベースのインスタンスを大きくする。【 No 】理由: スペック不足が原因でない場合、フェイルオーバーの失敗回避策にはなりません。Q10-4: データベースのフェイルオーバーを定期的にテスト（手動トリガー等）する。【 Yes 】理由: 高可用性構成が有事の際に正しく機能するかどうかを検証するため、平常時に定期的なフェイルオーバー演習（カオスエンジニアリング）を実施して動作確認することがベストプラクティスです。【問題11：App EngineのDBクエリ最小化（専用Memcache）】要件: Cloud SQLをバックエンドとするApp Engineアプリで、データベースへのクエリ発行数を最小限にしたい。Q11-1: memcacheのサービスレベルを専用に設定し、1分ごとに実行されるcronタスクで結果を投入する。【 No 】理由: 定期的なcronによる一括キャッシュ更新は不要なクエリまで発行することになり、DB負荷の最小化に逆行します。Q11-2: memcacheのサービスレベルをshared（共有）に設定し、cached_queriesというキーでDBの値を返す。【 No 】理由: 共有Memcacheは容量が保証されないためキャッシュヒット率が安定せず、DB負荷低減策として確実ではありません。Q11-3: memcacheのサービスレベルをshared（共有）に設定し、1分ごとのcronタスクで結果を保存する。【 No 】理由: 同様に共有キャッシュとcronの組み合わせは不適切です。Q11-4: memcacheのサービスレベルを専用に設定し、クエリハッシュからキーを作成してCloud SQLにクエリを発行する前にキャッシュの値をチェックする。【 Yes 】理由: 容量が保証される「専用Memcache」を使用し、リクエストの都度ハッシュキーでキャッシュを確認する（キャッシュアサイドアプローチ）ことで、データベースへの不要なクエリを最も効率的に削減できます。【問題12：Hadoopジョブのクラウド移行によるコスト最小化】要件: データサイエンスチームのHadoopジョブを、コード基盤を変更せずにインフラ管理の手間とコストを最小化してGCPに移行したい。Q12-1: 標準的なインスタンスを使用して、Compute Engineに手動でHadoopクラスタを展開する。【 No 】理由: 手動展開はインフラ管理の手間が大きく、標準インスタンスではコスト最小化の要件を満たしません。Q12-2: 標準的なワーカーインスタンスを使用してDataprocクラスタを作成する。【 No 】理由: Dataprocで手間は省けますが、標準ワーカーではコスト最小化の要件を満たしきれません。Q12-3: プリエンプト可能なインスタンスを使用して、Compute Engineに手動でHadoopクラスタを展開する。【 No 】理由: コストは下がりますが、手動展開によるインフラ管理のオーバーヘッドが残ります。Q12-4: プリエンプティブル ワーカー インスタンスを使用して Dataproc クラスタを作成する。【 Yes 】理由: フルマネージドHadoop環境であるDataprocを利用することでインフラ管理の手間を省き、ワーカーノードに安価なプリエンプティブルVMを指定することでコストを最小化できます。【問題13：GKEからの安全なアウトバウンド通信（NAT）】要件: 外部IPを持たない（許可されていない）GKEクラスタから、インターネット上のサードパーティサービスへ安全にアクセスしたい。Q13-1: Compute Engineインスタンスを作成しNATプロキシをインストールし、GKE上の全トラフィックを経由させる。【 No 】理由: 独自のNATプロキシの運用は管理オーバーヘッドが高く、単一障害点になるリスクがあります。Q13-2: GKEクラスターをプライベートクラスターとして構成し、VPC上でプライベートGoogleアクセスを構成する。【 No 】理由: プライベートGoogleアクセスはGCP内部サービスへのアクセス用であり、インターネット上のサードパーティAPIへのアクセスはできません。Q13-3: GKEクラスタをルートベースのクラスタとして構成し、VPC上にプライベートGoogleアクセスを構成する。【 No 】理由: 同様に、サードパーティへのインターネットアクセス要件を満たせません。Q13-4: GKEクラスターをプライベートクラスターとして設定し、クラスターのサブネットにCloud NAT Gatewayを設定する。【 Yes 】理由: パブリックIPを持たないプライベートGKEクラスタのノードがインターネットへアクセスするには、マネージドなCloud NATゲートウェイを配置するのが安全でスケーラブルなベストプラクティスです。【問題14：時系列センサーデータの保存】要件: 50,000個のセンサーから毎秒10回の読み取り（タイムスタンプと値）を行う天気図データのパフォーマンスを最適化して保存したい。Q14-1: Google Cloud Storageを使用する。【 No 】理由: 毎秒50万回の細かい書き込み（I/O）を直接Cloud Storageに対して行うのは適していません。Q14-2: Google Cloud SQLを使用する。【 No 】理由: リレーショナルDBでは毎秒50万回の書き込みスループットを処理できません。Q14-3: Google BigQueryを使用する。【 No 】理由: BigQueryへのストリーミングも可能ですが、高速なリアルタイムの書き込みと読み込み（Key-Valueアクセス）が両立する用途にはNoSQLが勝ります。Q14-4: Google Cloud Bigtableを使用する。【 Yes 】理由: Bigtableは高スループットの書き込みと時系列データ（タイムスタンプを持つデータ）のネイティブサポートを備えており、IoTや大量のセンサーデータ処理に最適なNoSQLです。【問題15：CI/CDでのテストとデプロイの連動】要件: リポジトリへの変更を自動でビルド・テストし、成功した検証済みのコンテナイメージのみを開発環境に自動デプロイしたい。Q15-1: プリコミットフックを各開発者のワークステーションにインストールし、手動でデプロイさせる。【 No 】理由: 手動デプロイに依存するため、自動化と監査性の要件に反します。Q15-2: Cloud Buildプロセスの一部として、ビルドツールの権限のみで新しいイメージを開発クラスタにデプロイする（パイプラインが分離されていない）。【 No 】理由: ビルドとデプロイの権限が分離されておらず、パイプラインとしてのガバナンスが不十分です。Q15-3: ポストコミットフックをリモートリポジトリにインストールし、開発者に手動でデプロイさせる。【 No 】理由: 同様に手動デプロイは要件を満たしません。Q15-4: Cloud Buildトリガーを作成しコードテストとイメージ保存を行い、新イメージを監視するデプロイメントパイプラインを作成し、専用ツールのみにデプロイ権限を与える。【 Yes 】理由: ビルド処理（CI）とデプロイ処理（CD）を明確なパイプラインとして分離し、専用のデプロイメントツールにのみデプロイ権限を持たせるのが、DevSecOpsのベストプラクティスです。【問題16：グローバルなKubernetes Ingressの構成】要件: us-central1にあるGKEクラスタのWeb APIを、アジアのユーザーにも低遅延で提供するためマルチリージョンへ拡張したい。Q16-1: クラスタ内のアプリケーションに割り当てるメモリとCPUを増やす。【 No 】理由: リソースを増やしても、地理的な物理距離によるネットワーク遅延（レイテンシ）は解決しません。Q16-2: クラウドCDNを有効にしたグローバルHTTPロードバランサーを使用する。【 No 】理由: CDNは静的コンテンツのキャッシュに有効ですが、API（動的データ）のレイテンシ改善には、ユーザーに近いリージョンでコンピュートを動かす必要があります。Q16-3: 第2のGKEクラスターを作成し、LoadBalancerタイプのサービスを使用してパブリックIPをDNSゾーンに追加する。【 No 】理由: 個別のLBとDNS設定では、単一のエニーキャストIPで最適なリージョンへルーティングするグローバルLBの利点を活かせません。Q16-4: asia-southeast1に第2のGKEクラスターを作成し、kubemci（またはAnthos Ingress）を使用してグローバルHTTP(S)ロードバランサーを作成する。【 Yes 】理由: ユーザーに近い別リージョンにクラスタをデプロイし、マルチクラスタIngressを利用してグローバルロードバランサで束ねることで、単一IPでユーザーを最寄りのクラスタへルーティングし遅延を最小化できます。【問題17：マイクロサービス障害のシミュレーション】要件: GKE上で動作するアプリケーションにおいて、特定のマイクロサービスが突然クラッシュした際のレジリエンス動作を検証したい。Q17-1: 挙動を観察するために、Kubernetesクラスタのノードの1つを破壊する。【 No 】理由: ノード全体の破壊はインフラ障害テストであり、アプリケーションレイヤーの特定の「マイクロサービスのクラッシュ」を正確にシミュレートできません。Q17-2: Kubernetesクラスタのノードにtaintを追加し、アンチアフィニティラベルを設定する。【 No 】理由: スケジューリングの制御機能であり、障害シミュレーションの手法ではありません。Q17-3: Istioのトラフィック管理機能を使って、クラッシュしたマイクロサービスからトラフィックを誘導する。【 No 】理由: 障害時の回避策の設定であり、障害自体を人工的に発生（シミュレート）させる機能ではありません。Q17-4: Istioのフォールト・インジェクション機能を、不具合のある動作をシミュレートしたい特定のマイクロサービスに使用する。【 Yes 】理由: サービスメッシュ（Istio/Anthos）のフォールトインジェクション機能を利用することで、コードを変更せずに意図的な遅延やHTTPエラー（クラッシュ）を挿入し、安全に障害テスト（カオスエンジニアリング）を実施できます。【問題18：Firewall Insightsのログ欠落解決】要件: Network Intelligence CenterのFirewall Insightsダッシュボードで、ルールの効率を評価したいが表示されるログ行がない問題を解決したい。Q18-1: ユーザーアカウントにcompute.networkAdminのIAMロールが割り当てられていることを確認する。【 No 】理由: 権限があっても、ログ自体の取得機能がオンになっていなければインサイトは生成されません。Q18-2: Google Cloud SDKをインストールし、コマンドライン出力にFirewallのログがないことを確認する。【 No 】理由: 表示されない原因の調査にはならず、問題解決の手段として不適切です。Q18-3: Virtual Private Cloud（VPC）のフローロギングを有効にする。【 No 】理由: フローログはサブネット全体のトラフィック記録用であり、ファイアウォールルール個別のインサイト分析には専用のロギングが必要です。Q18-4: 監視したいファイアーウォールルールの「ファイアーウォールルールロギング」を有効にする。【 Yes 】理由: Firewall Insightsがメトリクスと分析情報を生成するためには、大前提として各VPCファイアウォールルールのロギング機能が有効になっている必要があるためです。【問題19：大量センサーデータのメタ情報結合】要件: 1000の会議室から毎秒送られるモーションセンサーデータ（非構造化データ）とアカウント情報を紐付けて追跡・分析したい。Q19-1: リレーショナルデータベースを使用する。【 No 】理由: 高速かつ連続的に生成される非構造・半構造のセンサーデータにはRDBMSはスループットやスキーマの観点で不向きです。Q19-2: フラットファイルを使用する。【 No 】理由: ファイル出力ではメタ情報との結合や即座のクエリ分析ができません。Q19-3: Blobストアを使用する。【 No 】理由: Blobストア（Cloud Storage等）は保存には適していますが、他のデータと紐付けて即時検索する用途には適していません。Q19-4: NoSQLデータベースを使用する。【 Yes 】理由: 連続生成される大量のセンサーデータ（非構造化データ）の書き込みスループット要件を満たしつつ、柔軟なスキーマで関連情報を保存・分析するにはNoSQLデータベースが最適解となります。【問題20：Cloud Storageアップロードの整合性確認】要件: Cloud Storageへアップロードした重要ファイルがオンプレミスのものと同一であることを、コストと労力を最小限に抑えて確認したい。Q20-1: アップロード後、ダウンロードしてLinux diffで比較する。【 No 】理由: 再度ダウンロードする通信コストと時間がかかり、「最小限に抑える」要件に反します。Q20-2: Linux shasumで計算後アップロードし、ダウンロードしてshasumで比較する。【 No 】理由: 同様に、ダウンロードによる通信オーバーヘッドが大きく非効率です。Q20-3: アップロード後、CRC32Cハッシュを計算するカスタムJavaアプリケーションを開発し、gsutil ls -L と比較する。【 No 】理由: `gsutil` に組み込まれているハッシュ計算機能を活用せず、自前でアプリを開発するのは労力がかかりすぎます。Q20-4: gsutil -m でアップロード後、gsutil hash -c でローカルのハッシュを取得し gsutil ls -L の出力と比較する。【 Yes 】理由: ダウンロードし直すことなく、ローカルのツールで計算したハッシュ値と、Cloud Storage上のメタデータとして保持されているハッシュ値を直接比較することで、最小限の通信コストと労力でデータの整合性を確認できます。