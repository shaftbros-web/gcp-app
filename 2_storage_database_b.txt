【カテゴリ2：ストレージとデータベース】全116問の回答と理由【問題1：Cloud SQLのゾーン障害耐性】 要件: SQL Serverを構築する際、ゾーン障害時でもダウンタイムが発生しないようにしたい。• Q1-1: Cloud Spannerをリージョン構成にする。◦ 【 No 】理由: SQL Serverをセットアップするという要件に対し、Cloud Spannerは異なるデータベースサービスであるため要件を満たしません。• Q1-2: 高可用性(HA)を有効にしてCloud SQLを構成する。◦ 【 Yes 】理由: Cloud SQLのHA構成（リージョンインスタンス）は、プライマリゾーンとセカンダリゾーンに配置され、ゾーン障害時のダウンタイムを削減できるため最適です。• Q1-3: GCEでWindows Failover Clusteringをゾーン跨ぎで構築する。◦ 【 No 】理由: 自前でクラスタリングを構築することは可能ですが、インフラ管理の手間がかかるため、マネージドサービスであるCloud SQLを利用する方がベストプラクティスです。• Q1-4: GCEでWindows Failover Clusteringを別サブネットで構築する。◦ 【 No 】理由: サブネットを分けるだけではゾーン間の物理的な障害に対する耐性（可用性）を確保できるとは限らないため不適切です。【問題2：Bigtableのホットスポット解消】 要件: Bigtableでのクエリ時間増大（ホットスポット）を解決し、パフォーマンスを回復させたい。• Q2-1: 30日以上前のレコードを削除する。◦ 【 No 】理由: 古いデータを削除しても、リアルタイムの書き込みや読み込みが特定のキーに集中する「ホットスポット」の根本的な解決にはなりません。• Q2-2: RowKey戦略を見直し、キーが均等に分散するようにする。◦ 【 Yes 】理由: Bigtableのホットスポットは行キーの分散に偏り（タイムスタンプの連続使用など）がある場合に発生するため、キーがアルファベット順などで均等に分散する戦略に見直すのが正解です。• Q2-3: ノード数を2倍にする。◦ 【 No 】理由: キーの設計が悪いままノードを増やしても、特定のノードにのみ負荷が集中する状態は変わらないため解決しません。• Q2-4: NodeJS APIではなくHBase APIを使うようアドバイスする。◦ 【 No 】理由: APIの言語や種類を変更しても、データ構造の偏りであるホットスポットは解消されません。【問題3：Cloud SQLのフェイルオーバー】 要件: Cloud SQLで特定のゾーンから提供を行っており、新たに高可用性（HA）を導入したい。• Q3-1: 異なるリージョンにリードレプリカを作成する。◦ 【 No 】理由: リードレプリカは読み取り性能の向上用であり、HA（高可用性）のためのフェイルオーバーには使用されません。• Q3-2: 同じリージョンの異なるゾーンにリードレプリカを作成する。◦ 【 No 】理由: 同様に、リードレプリカは高可用性（フェイルオーバー）の目的には適していません。• Q3-3: 同じリージョンの別のゾーンにフェイルオーバーレプリカを作成する。◦ 【 Yes 】理由: Cloud SQLの高可用性を実現するには、同じリージョン内の別のゾーンにフェイルオーバーレプリカを作成するのが正しい設定です。• Q3-4: フェイルオーバーレプリカを別のリージョンに作成する。◦ 【 No 】理由: Cloud SQLはリージョナルサービスであり、HA構成（フェイルオーバー）は同一リージョン内でのみ構成可能です。【問題4：GCEの共有POSIXファイルシステム】 要件: ステートフルワークロードで、全インスタンスが同じPOSIXファイルシステムに100MB/sで読み書きしたい。• Q4-1: Cloud Storageバケットをgcsfuseでマウントする。◦ 【 No 】理由: gcsfuseはPOSIXに完全互換ではなく、100MB/sの高スループットや低レイテンシのステートフル要件には適していません。• Q4-2: 各インスタンスにリージョナル永続ディスクを使用する。◦ 【 No 】理由: 永続ディスクはブロックストレージであり、複数のインスタンスから同時に読み書きする共有ファイルシステムとしては構成できません。• Q4-3: Cloud Filestoreインスタンスを作成し各インスタンスにマウントする。◦ 【 Yes 】理由: Cloud Filestoreは高パフォーマンスなマネージドの共有ファイルストレージであり、複数のVMやPodから同じデータへPOSIX互換でアクセスする要件に最適です。• Q4-4: 各インスタンスに永続ディスクを使用する。◦ 【 No 】理由: 個別の永続ディスクでは「全インスタンスで同じファイルシステムを共有する」要件を満たせません。【問題5：Cloud Storageのライフサイクル管理】 要件: 90日以上前のバックアップをCloud Storageから削除し、費用を最適化したい。• Q5-1: gsutil ls -lr とcronジョブを使って削除スクリプトを回す。◦ 【 No 】理由: 自前でcronジョブを管理するのは運用負荷が高く、クラウドネイティブなベストプラクティスではありません。• Q5-2: ライフサイクルルールをXMLで記述しプッシュする。◦ 【 No 】理由: ライフサイクル設定はJSON形式で記述してプッシュするのが正しい手順です。• Q5-3: ライフサイクルルールをJSONで記述し、gsutilでバケットにプッシュする。◦ 【 Yes 】理由: ライフサイクル管理ルールをJSONドキュメントで記述し、API（またはgsutil lifecycle set）で適用することで、指定日数経過後の自動削除を運用負荷なく実現できます。• Q5-4: gsutil ls -l とcronジョブを使って削除スクリプトを回す。◦ 【 No 】理由: スクリプトでの削除運用は非推奨であり、また ls -l ではバージョン管理されたオブジェクトを完全に削除できない可能性があります。【問題6：分析用データウェアハウス（BigQuery）】 要件: 過去のレースデータを保持し、スキーマへのカラム追加とスケーラビリティを備えた分析基盤を作りたい。• Q6-1: Cloud SQLを使用し、シーズンごとに別インスタンスにする。◦ 【 No 】理由: 大規模な分析（データウェアハウス）や柔軟なスキーマ変更の要件に対し、リレーショナルDBであるCloud SQLを複数立てるのは非効率です。• Q6-2: Cloud Spannerを使用し、シーズンを主キーにする。◦ 【 No 】理由: SpannerはグローバルなトランザクションDBであり、分析（OLAP）用途のデータウェアハウスとしては最適ではありません。• Q6-3: BigQueryを使用し、シーズンに基づいてパーティション分割する。◦ 【 Yes 】理由: BigQueryはスケーラビリティに優れたサーバーレスのデータウェアハウスであり、カラムの追加が容易で、パーティション分割により分析コストとパフォーマンスを最適化できます。• Q6-4: Firestoreを使用し、コレクションで集約する。◦ 【 No 】理由: FirestoreはドキュメントベースのNoSQLであり、複雑な分析クエリやデータウェアハウス用途には適していません。【問題7：ストリーミングデータの保存（Bigtable）】 要件: 毎秒最大8,500件のストリーミングデータをリアルタイムで保存し、将来の分析に備えたい。• Q7-1: Google Cloud SQLを使用する。◦ 【 No 】理由: 毎秒数千件のリアルタイムストリーミングデータの書き込みには、リレーショナルDBのCloud SQLではスループットが不足する可能性があります。• Q7-2: Google Cloud Datastoreを使用する。◦ 【 No 】理由: Datastoreはトランザクションや階層データには適していますが、超高速な時系列イベントのストリーミング書き込みには最適ではありません。• Q7-3: Google Cloud Bigtableを使用する。◦ 【 Yes 】理由: Bigtableはリアルタイムアクセスと分析ワークロードの両方に適した、低レイテンシで高スループットのNoSQLデータベースであり、クリックデータやIoTデータの保存に最適です。• Q7-4: Google Cloud Storageを使用する。◦ 【 No 】理由: オブジェクトストレージは毎秒数千の細かいストリーミングデータの直接の書き込み先としては不適切です。【問題8：グローバルな静的ファイル配信】 要件: 世界中の顧客に配信する静的ファイルのダウンロード遅延を最小限に抑えたい。• Q8-1: リージョンとゾーンごとに1つのバケットを作成する。◦ 【 No 】理由: 管理が極めて煩雑になり、世界中からのリクエストを適切にルーティングする仕組みを自前で作る必要があります。• Q8-2: 1つのMulti-Regional Cloud Storageバケットに保存する。◦ 【 No 】理由: 1つのマルチリージョンバケット（例：USのみ）では、他の大陸（EUやアジアなど）のユーザーに対しては遅延が大きくなります。• Q8-3: リージョンごとに1つのバケットを作成する。◦ 【 No 】理由: 同様に管理が煩雑であり、グローバルな配信には適していません。• Q8-4: 複数のMulti-Regional Cloud Storageバケットに保存しマルチリージョンごとに分ける。◦ 【 Yes 】理由: 「米国」「EU」「アジア」など複数の大陸（マルチリージョン）ごとにバケットを作成し配置することで、世界中のユーザーに近い場所から配信でき、遅延を最小化できます。【問題9：Cloud Storageの改ざん防止（バケットロック）】 要件: ローン承認書類を、アップロード後5年間は削除や上書きができないよう完全に保護したい。• Q9-1: KMSで暗号化し、5年後に鍵をローテーションする。◦ 【 No 】理由: 暗号化はデータの秘匿性を守るものであり、データ自体の「削除や上書き（改ざん）」を防ぐものではありません。• Q9-2: IAMオブジェクトライター権限でサービスアカウントを使う。◦ 【 No 】理由: IAM権限だけでは、権限を持つユーザーによる誤削除や悪意のある上書きをシステム的に完全に防ぐことはできません。• Q9-3: バケットに5年間の保持ポリシーを作成し、ロックをかける。◦ 【 Yes 】理由: バケットロック機能を使用すると、指定した保持期間（5年）が経過するまでオブジェクトの削除や置き換えをシステムレベルで完全に禁止でき、コンプライアンス要件を満たせます。• Q9-4: バケットレベルの均一なアクセス権で運用する。◦ 【 No 】理由: アクセス権の均一化は権限管理の簡素化であり、データの削除防止（リテンションポリシー）機能ではありません。【問題10：Cloud StorageのAPIリクエスト制限】 要件: Cloud Storageへのリクエストで発生する5xxや429エラーに対処したい。• Q10-1: Google Cloudステータスを監視し、障害時以外にリクエストする。◦ 【 No 】理由: 429（Too Many Requests）等は自身のアプリのリクエスト過多が原因であり、Google側の障害監視では解決しません。• Q10-2: HTTPの代わりにgRPCを使用する。◦ 【 No 】理由: プロトコルを変えても、ストレージのスケーリング上限を超えるリクエストレートの問題は解決しません。• Q10-3: 指数的バックオフ戦略を使用したリトライロジックを実装する。◦ 【 Yes 】理由: Cloud Storageのキャパシティ超過エラー（429や5xx）に対しては、徐々に待機時間を延ばして再試行する「指数的バックオフ」を実装するのが公式のベストプラクティスです。• Q10-4: バケットがマルチリージョンであることを確認し冗長性を確保する。◦ 【 No 】理由: マルチリージョンにしても、急激なリクエストレート超過によるエラー自体は防げません。【問題11：多様なストレージ要件の割り当て】 要件: ログ、ブートボリューム、サムネイル画像、セッション状態データをコスト効率よく保存したい。• Q11-1: セッションはPD SSD、他はCloud Storageに保存する。◦ 【 No 】理由: セッションデータにブロックストレージ（PD SSD）を使用するのはスケーラビリティや構造の観点から非効率です。• Q11-2: セッションはCloud SQL、他はCloud Storageに保存する。◦ 【 No 】理由: セッションデータのような揮発性が高く高速な読み書きが必要なデータにリレーショナルDB（Cloud SQL）はコスト過多です。• Q11-3: セッションはローカルSSD、他はCloud Storageに保存する。◦ 【 No 】理由: ローカルSSDはVMが停止するとデータが消えるため、「数日間オフラインでも再開できる」という要件を満たせません。• Q11-4: セッションはDatastoreバックアップのMemcache、他はCloud Storageに保存する。◦ 【 Yes 】理由: ログや画像、カスタムイメージ（ブート）はCloud Storageに安価に保存し、セッションデータは高速なMemcacheに置きつつDatastoreで永続化（バックアップ）するのが最もコスト効率の高い設計です。【問題12：大容量データのネットワーク移行】 要件: 10TBのオンプレミスDBを、1Gbpsの帯域を使いコストと時間を最小化して移行したい。• Q12-1: gsutil -m でデータを圧縮しマルチスレッドコピーでアップロードする。◦ 【 Yes 】理由: 10TBと1Gbpsの条件下ではネットワーク転送で約30時間で完了するため、物理デバイスの郵送を待つよりもネットワーク転送（gsutilのマルチスレッド）が最速かつ低コストです。• Q12-2: 商用パートナーのETLソリューションを使う。◦ 【 No 】理由: サードパーティツールは追加コストがかかり、「コストを最小化」する要件に反します。• Q12-3: DBから直接読み込むDataflowジョブを開発する。◦ 【 No 】理由: 開発のオーバーヘッド（時間）がかかるため、単純なデータ移行のベストプラクティスではありません。• Q12-4: Transfer Applianceを使用してオフライン移行する。◦ 【 No 】理由: Transfer Applianceの配送〜アップロードには約20日かかるため、10TB規模であればネットワーク転送の方が早く完了します。【問題13：永続ディスクのIOPS向上】 要件: 80GBのSSD永続ディスクを搭載したMySQLサーバーのパフォーマンス（IOPS）を向上させたい。• Q13-1: PostgreSQLに作り直す。◦ 【 No 】理由: DBエンジンを変更しても、根底にあるディスクのI/Oパフォーマンスの制約は解決しません。• Q13-2: 仮想マシンのメモリを64GBに増設する。◦ 【 No 】理由: メモリを増やしてもディスク自体のIOPS上限は上がりません。• Q13-3: SSD永続ディスクのサイズを動的に500GBに変更・拡張する。◦ 【 Yes 】理由: Google Cloudの永続ディスクのパフォーマンス（IOPSとスループット）はディスク容量に比例するため、サイズを拡張することでIOPSが向上しパフォーマンス問題が解決します。• Q13-4: データベースへの一括挿入を使用するようにジョブを変更する。◦ 【 No 】理由: アプリ側の修正だけでは、インフラ層のIOPS上限のボトルネックは解消されません。【問題14：クレジットカード情報のトークン化保存】 要件: カードデータをトークン化し、重複を排除しつつ平文を保存せずに低遅延で処理したい。• Q14-1: 決定論的アルゴリズムで暗号化しMemorystoreにシャードする。◦ 【 No 】理由: Memorystore（Redis等）はインメモリキャッシュであり、永続的なトークンストアとしては耐久性に欠けます。• Q14-2: Secret Managerに保存する。◦ 【 No 】理由: Secret ManagerはAPIキーやパスワードの保存用であり、大量の顧客カードデータの保存と検索には適していません。• Q14-3: 列レベル暗号化を使用してCloud SQLに保存する。◦ 【 No 】理由: トークン化と重複排除の要件に対し、リレーショナルDBでの暗号化管理は処理遅延やスケーラビリティの課題が生じます。• Q14-4: データストアモードのFirestoreに決定論的アルゴリズムで暗号化して保存する。◦ 【 Yes 】理由: 同じ入力から同じトークンを生成する決定論的アルゴリズムを使うことで重複排除が可能になり、Firestore（Datastoreモード）は数百万回の書き込みを低遅延で処理できるため要件に最適です。【問題15：ゾーン障害時のデータ復旧（リージョナルPD）】 要件: ゾーン障害時に、別のゾーンで最新のアプリケーションデータを使って即座に復旧させたい。• Q15-1: リージョナルPDを使い、そのまま運用する。◦ 【 No 】理由: リージョナルPDを準備するだけでは、障害時に新しいVMを立ち上げてアタッチするプロセスが抜けています。• Q15-2: リージョナルPDを使い、障害時にインスタンステンプレートで別ゾーンにスピンアップする。◦ 【 Yes 】理由: 2つのゾーン間でデータを同期レプリケーションする「リージョナル永続ディスク」を利用し、障害時は別ゾーンでインスタンスをスピンアップ（強制アタッチ）することで、データ損失なしで即座に復旧できます。• Q15-3: ゾーンPDの最新スナップショットから同じゾーンに復元する。◦ 【 No 】理由: ゾーン全体がダウンしている場合、同じゾーン内での復元は不可能です。• Q15-4: ゾーンPDの最新スナップショットから別ゾーンに復元する。◦ 【 No 】理由: スナップショットからの復元では、直近のスナップショット取得以後の「最新データ」が失われるため、即時かつ最新のデータでの復旧要件を満たしません。【問題16：永続ディスクの容量拡張（無停止）】 要件: ext4形式の永続ディスク容量が逼迫しており、ダウンタイム最小で修復（拡張）したい。• Q16-1: 新しいPDを作成しマウントし直す。◦ 【 No 】理由: データの移行やマウントし直しに伴うダウンタイムが発生するため不適切です。• Q16-2: コンソールでサイズを増やし、Linuxの resize2fs コマンドを使用する。◦ 【 Yes 】理由: Google Cloudでは無停止でディスクサイズを拡張でき、OS側で resize2fs コマンドを実行してファイルシステムを拡張することで、ダウンタイムなしで修復可能です。• Q16-3: コンソールでサイズを増やし、Linuxの fdisk コマンドを使用する。◦ 【 No 】理由: fdisk はパーティションを作成するコマンドであり、既存のファイルシステムの拡張には resize2fs が必要です。• Q16-4: 仮想マシンをシャットダウンしてサイズを増やし再起動する。◦ 【 No 】理由: シャットダウンを行うとダウンタイムが発生するため、「ダウンタイムを最小にする」という要件に反します。【問題17：Cloud SQLのデータ損失最小化】 要件: Cloud SQL (MySQL) で致命的な障害が発生した場合のデータ損失を最小限にしたい。（※複数選択の要件を個別に判定）• Q17-1: リードレプリカを実装する。◦ 【 No 】理由: リードレプリカは読み取り性能のスケール用であり、障害時のデータ復旧（ポイントインタイムリカバリ）には使用しません。• Q17-2: バックアップの自動化を実装する。◦ 【 Yes 】理由: 自動バックアップを有効にすることで、障害前の状態にデータベースを復元するためのベースが確保されます。• Q17-3: シャーディングを実装する。◦ 【 No 】理由: シャーディングはパフォーマンスや容量向上のための水平分割であり、データ損失防止機能ではありません。• Q17-4: バイナリロギングを実装する。◦ 【 Yes 】理由: 自動バックアップに加えてバイナリログを有効にすることで、障害発生直前までの「ポイントインタイムリカバリ」が可能になり、データ損失を極小化できます。【問題18：大量リクエストと高速検索（Bigtable）】 要件: 毎秒50万件のリクエストを完全一致で検索・保存し、インフラコストを最小限に抑えたい。• Q18-1: Compute EngineのMIGとBigQueryを使用する。◦ 【 No 】理由: BigQueryは分析用ウェアハウスであり、毎秒50万件のミリ秒単位での完全一致検索（OLTP/Key-Valueアクセス）には適していません。• Q18-2: Cloud RunとBigQueryを使用する。◦ 【 No 】理由: 同様に、BigQueryは要件を満たすデータベースではありません。• Q18-3: Cloud RunとCloud Bigtableを使用する。◦ 【 Yes 】理由: Cloud Runはトラフィックに応じたオートスケール（ゼロスケール含む）でコストを最適化し、Cloud Bigtableは毎秒数百万回の低遅延な読み書きをサポートするため、この組み合わせが最適です。• Q18-4: Compute EngineのMIGとCloud Bigtableを使用する。◦ 【 No 】理由: GCEのMIGはプロビジョニングされたインスタンスが常時稼働するため、非トラフィック時のインフラコストを最小化するという要件において、サーバーレスのCloud Runに劣ります。【問題19：オンプレミスDBの最小ダウンタイム移行】 要件: オンプレミスのMySQLからCloud SQLへ、ダウンタイムと変更を最小限に抑えて移行したい。• Q19-1: VPN接続後、オンプレを停止しCloud SQLのレプリカをプロモートして切り替える。◦ 【 Yes 】理由: オンプレミスDBの外部レプリカとしてCloud SQLを設定し、同期が完了した時点でオンプレ側を停止してCloud SQLをスタンドアロン（マスター）に昇格させる方法が、最もダウンタイムが少ないベストプラクティスです。• Q19-2: mysqldumpを作成しインポート後、両方に書き込むようアプリを変更する。◦ 【 No 】理由: アプリケーション側の改修（両方への書き込みロジックの追加）が必要となり、「最小限の変更」の要件に反します。• Q19-3: Cloud SQL ProxyとMySQL Proxyを設定し、ダンプで移行する。◦ 【 No 】理由: ダンプとインポートのみでは、インポート中のデータ変更が反映されないためダウンタイムが長くなります。• Q19-4: オンプレを停止後、mysqldumpを作成しインポートして起動する。◦ 【 No 】理由: ダンプ作成からアップロード、インポートが完了するまでシステム全体を停止する必要があり、ダウンタイムが最大化してしまいます。【問題20：Cloud Storageへの顧客提供鍵（CSEK）適用】 要件: クライアントが用意した暗号化キー(CSEK)を使って、Cloud Storage上のファイルを暗号化したい。• Q20-1: gsutilのフラグ --encryption-key で指定する。◦ 【 No 】理由: gsutil には --encryption-key というコマンドラインフラグは存在しません。• Q20-2: gcloud config で暗号化キーを指定する。◦ 【 No 】理由: CSEKは gcloud config ではなく gsutil の設定ファイルに記述します。• Q20-3: gsutilを使ってファイルをアップロードし、フラグ--encryption-keyを使って暗号化キーを指定する。◦ 【 No 】理由: Q20-1と同様、フラグ指定は誤りです。• Q20-4: 暗号化キーを .boto 設定ファイルに記述し、gsutil でアップロードする。◦ 【 Yes 】理由: Cloud Storageで顧客提供の暗号鍵（CSEK）を使用する場合、ローカルの .boto 構成ファイル内に encryption_key として指定し gsutil コマンドを実行するのが正しい手順です。【問題21：データベースバックアップによるディスク影響の最小化】 要件: ディスクパフォーマンスに影響を与えず、できるだけ早くMySQLのバックアップを完了させたい。• Q21-1: gcsfuseでCloud Storageを直接マウントしmysqldumpする。◦ 【 No 】理由: ネットワーク越しでの直接書き込みは遅く、バックアップ完了までの時間がかかります。• Q21-2: cronジョブでPDスナップショットを定期取得する。◦ 【 No 】理由: ディスクスナップショット取得時はI/Oが一時的に停止・遅延する可能性があり、パフォーマンスに影響を与えない要件に反します。• Q21-3: ローカルSSDをバックアップ先とし、完了後にgsutilでCloud Storageに移動する。◦ 【 Yes 】理由: 超高速なローカルSSDにダンプを書き込むことでDBのディスク負荷と時間を最小化し、完了後にCloud Storageへ転送する2段階アプローチがベストプラクティスです。• Q21-4: RAID10でマウントしLVMスナップショットを使う。◦ 【 No 】理由: 構成が複雑化し、クラウドリソースのネイティブな利点を活かしていません。【問題22：アクティブ・パッシブ構成の即時フェイルオーバー】 要件: ゾーン障害時に、即座にもう一方のゾーンのインスタンスでデータを利用できるようにしたい。• Q22-1: Cloud Storageバケットを gcs-fuse で両方にマウントする。◦ 【 No 】理由: パフォーマンス要件を満たせず、ブロックストレージの代替にはなりません。• Q22-2: リージョナルSSD永続ディスクを使用し、障害時に別インスタンスに強制的に取り付ける。◦ 【 Yes 】理由: リージョナル永続ディスクは2つのゾーン間でデータを同期しており、障害発生時は --force-attach フラグで別ゾーンのスタンバイVMにアタッチすることで即時フェイルオーバーが可能です。• Q22-3: PD SSDの1時間ごとのスナップショットから再作成する。◦ 【 No 】理由: 最大1時間分のデータが失われ、再作成に時間がかかるため「即座に」という要件を満たしません。• Q22-4: ローカルSSDに rsync コマンドで1時間ごとに同期する。◦ 【 No 】理由: 同期遅延によるデータ損失が発生し、障害検知時の即時切り替えの仕組みがありません。【問題23：ペタバイト級データのオフライン移行】 要件: 500TBのデータを1Gbpsの帯域制限下で、推奨プラクティスに従いCloud Storageに移行したい。• Q23-1: データをTransfer Applianceに移動し、Cloud Dataprepで復号する。◦ 【 No 】理由: 暗号化されたアプライアンスのデータをクラウド上で復元するツールはDataprepではありません。• Q23-2: gsutilのストリーミング転送を使用してアップロードする。◦ 【 No 】理由: 1Gbpsで500TBを転送すると46日以上かかるため、ネットワーク経由は不適切です。• Q23-3: gsutilの再開可能な転送を使用してアップロードする。◦ 【 No 】理由: 同様に帯域制限により時間がかかりすぎます。• Q23-4: データをTransfer Applianceに移動し、RehydratorでCloud Storageに復号する。◦ 【 Yes 】理由: 物理アプライアンス（Transfer Appliance）を使用してオフラインで輸送し、クラウド到着後にRehydrator（復元ツール）を使用してデータを復号・保存するのが、大規模データ移行の最短かつ安全な方法です。【問題24：変化する非構造化データの保存】 要件: 構造変更が頻繁な非構造化データを、取得したままの状態でデータレイクに保存したい。• Q24-1: BigQueryテーブルに保存し、パイプラインを設計する。◦ 【 No 】理由: 構造が頻繁に変わる非構造化データを直接BigQuery（構造化データウェアハウス）に保存することはできません。• Q24-2: Cloud Storageバケットに保存し、バケットから取り出すパイプラインを設計する。◦ 【 Yes 】理由: オブジェクトストレージであるCloud Storageはデータレイクとして最適であり、任意の形式の非構造化データを取得したままの状態で保存し、後段の処理パイプラインへ連携できます。• Q24-3: 処理済みのデータを再処理用にCloud Storageに保存する。◦ 【 No 】理由: 「処理済み」のデータではなく、「取得したままの状態（生データ）」で保存するという要件に反します。• Q24-4: 処理済みのデータを再処理用にBigQueryに保存する。◦ 【 No 】理由: 同様に、処理済みのデータを保存するアプローチは生データ保存の要件に反します。【問題25：Cloud Storageの顧客管理暗号鍵（CMEK）適用】 要件: 規制上の理由で、暗号化キーをクラウド外でローテーション可能にしてCloud Storageのデータを保護したい。• Q25-1: GPGキーで暗号化してからバケットにアップロードする。◦ 【 No 】理由: クライアント側で完全に暗号化する手間がかかり、マネージドなクラウドの利点を活かせません。• Q25-2: お客様提供の暗号化キー（CSEK）機能を使用する。◦ 【 No 】理由: CSEKはAPIコールごとにキーを提供する必要があり、中央管理されたローテーション等のガバナンスが効きにくいです。• Q25-3: Cloud KMSのencryptメソッドでデータを暗号化する。◦ 【 No 】理由: アプリケーション側で暗号化処理を組み込む必要があり、ストレージ側のネイティブ機能を活かしていません。• Q25-4: Cloud KMSで鍵を作成し、バケットの暗号化キーをCloud KMSのキーに設定する。◦ 【 Yes 】理由: 顧客管理の暗号鍵（CMEK）を使用することで、暗号化処理自体はCloud Storageに任せつつ、鍵の作成・管理・ローテーションをCloud KMSで一元管理（または外部キーマネージャーと連携）でき、規制要件を満たせます。【問題26：Cloud SQLの負荷・容量最適化】 要件: Cloud SQLのストレージ不足を回避し、CPU使用率を維持しつつ、レプリケーションラグを減らしたい。• Q26-1: ストレージ超過アラートを作成し容量追加、memcached導入、インスタンス変更を行う。◦ 【 No 】理由: 手動での容量追加は運用負荷が高く、自動増加機能を使うべきです。• Q26-2: ストレージ自動増加を有効化し、CPUアラートを作成してインスタンスを変更し、シャーディングする。◦ 【 Yes 】理由: ストレージ不足は「自動増加」で解決し、CPU維持は「アラート検知とマシンタイプ変更」で対応し、レプリケーションの遅延はデータベースを分割する「シャーディング」で解決するのがアーキテクチャとして正しいアプローチです。• Q26-3: ストレージ自動増加を有効化し、インスタンス変更、memcacheを導入する。◦ 【 No 】理由: キャッシュ（memcache）の導入ではDB自体のレプリケーションラグの根本解決（書き込み負荷の分散）にはなりません。• Q26-4: ストレージアラートを作成し、memcached導入、レプリケーションラグアラートでインスタンスを変更する。◦ 【 No 】理由: ストレージが手動管理になっており不適切です。【問題27：時系列センサーデータの保存】 要件: 5万個のセンサーから毎秒10回の読み取り（タイムスタンプと値）を行う天気図データを保存したい。• Q27-1: Google Cloud Storageを使用する。◦ 【 No 】理由: 毎秒50万回の細かい書き込み（I/O）を直接Cloud Storageに対して行うのは適していません。• Q27-2: Google Cloud Bigtableを使用する。◦ 【 Yes 】理由: Bigtableは高スループットの書き込みと、時系列データ（タイムスタンプを持つデータ）のネイティブサポートを備えており、IoTやセンサーデータに最適なNoSQLです。• Q27-3: Google Cloud SQLを使用する。◦ 【 No 】理由: リレーショナルDBでは毎秒50万回の書き込みスループットを処理できません。• Q27-4: Google BigQueryを使用する。◦ 【 No 】理由: BigQueryへのストリーミングインサートは可能ですが、高速なリアルタイムの書き込みと読み込み（Key-Valueアクセス）が両立する用途にはBigtableが勝ります。【問題28：大量センサーデータのメタ情報結合】 要件: 会議室のモーションセンサーデータ（毎秒更新）を保存し、アカウント情報等と紐付けて分析したい。• Q28-1: リレーショナルデータベースを使用する。◦ 【 No 】理由: 高速かつ連続的に生成される非構造・半構造のセンサーデータにはRDBMSはスループットやスキーマの観点で不向きです。• Q28-2: フラットファイルを使用する。◦ 【 No 】理由: ファイル出力ではメタ情報との結合や即座のクエリ分析ができません。• Q28-3: NoSQLデータベースを使用する。◦ 【 Yes 】理由: 連続生成されるセンサーデータの書き込みスループット要件を満たしつつ、柔軟なスキーマで関連情報を保存・分析するにはNoSQLデータベース（BigtableやFirestoreなど）が最適解となります。• Q28-4: Blobストアを使用する。◦ 【 No 】理由: Blobストア（Cloud Storage等）は分析用の即時クエリやメタデータの結合には適していません。【問題29：Cloud Storageアップロードの整合性確認】 要件: Cloud Storageアップロード後に、オンプレミスのファイルと同一かコストと労力を最小限で確認したい。• Q29-1: gsutil -m でアップロード後、gsutil hash でローカルのハッシュを取得し gsutil ls -L と比較する。◦ 【 Yes 】理由: ダウンロードし直すことなく、ローカルで計算したCRC32Cハッシュ値と、Cloud Storage上のメタデータ（gsutil ls -L）のハッシュ値を直接比較することで、最小限の通信コストと労力で整合性を確認できます。• Q29-2: アップロード後にダウンロードし、Linux diffで比較する。◦ 【 No 】理由: 再度ダウンロードする通信コストと時間がかかり、「最小限に抑える」要件に反します。• Q29-3: アップロード後にダウンロードし、Linux shasumで比較する。◦ 【 No 】理由: 同様に、ダウンロードによるオーバーヘッドが大きく非効率です。• Q29-4: CRC32Cハッシュを計算するカスタムJavaアプリを開発して比較する。◦ 【 No 】理由: gsutil に組み込まれているハッシュ計算機能を活用せず、自前でアプリを開発するのは労力がかかりすぎます。